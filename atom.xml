<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Blackwhole</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2017-07-02T21:36:04.000Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Jin HU</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2017/10/26/javascript/"/>
    <id>http://yoursite.com/2017/10/26/javascript/</id>
    <published>2017-10-26T12:04:26.823Z</published>
    <updated>2017-07-02T21:36:04.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Programming-and-the-Web-for-Beginners"><a href="#Programming-and-the-Web-for-Beginners" class="headerlink" title="Programming and the Web for Beginners"></a>Programming and the Web for Beginners</h1><h2 id="Week-1-HTML-and-CSS"><a href="#Week-1-HTML-and-CSS" class="headerlink" title="Week 1: HTML and CSS"></a>Week 1: HTML and CSS</h2><p>Title:</p><figure class="highlight html"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">h1</span>&gt;</span>hello<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">h2</span>&gt;</span>hello world<span class="tag">&lt;/<span class="name">h2</span>&gt;</span></div></pre></td></tr></table></figure><p><a href="http://www.dukelearntoprogram.com/course1/doc/" target="_blank" rel="external">documents</a></p><p>Week 2: Fundamentals with JavaScript</p><h2 id="Week-3-JavaScript-and-Web-Pag"><a href="#Week-3-JavaScript-and-Web-Pag" class="headerlink" title="Week 3: JavaScript and Web Pag"></a>Week 3: JavaScript and Web Pag</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Programming-and-the-Web-for-Beginners&quot;&gt;&lt;a href=&quot;#Programming-and-the-Web-for-Beginners&quot; class=&quot;headerlink&quot; title=&quot;Programming and th
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Distributed Algorithms C7 -- Consistent snapshot</title>
    <link href="http://yoursite.com/2017/03/07/DAlg-notes-C7/"/>
    <id>http://yoursite.com/2017/03/07/DAlg-notes-C7/</id>
    <published>2017-03-07T08:34:22.000Z</published>
    <updated>2017-03-08T08:44:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>• What is the problem with global snapshots?<br>• What is a global state?<br>• Which snapshot algorithms do you know?</p><p>snapshot problem</p><p>consistency criterion for consistent cuts</p><p>snapshot algorithms</p><p>snapshot applications</p><a id="more"></a><h2 id="The-snapshot-problem"><a href="#The-snapshot-problem" class="headerlink" title="The snapshot problem"></a>The snapshot problem</h2><p>Determine “current” snapshot of the global state without stopping the system.</p><p>One cannot catch all processes at the same time, messages that are on the way cannot be seen.</p><p>The determined state should at least be <strong>consistent</strong>, the saved state should not be influenced by future messages.</p><h3 id="Global-state"><a href="#Global-state" class="headerlink" title="Global state"></a>Global state</h3><p>The execution of each process in the distributed system can be characterized by its history: $history(p_i) = h_i=<e^0_i,e^1_i,e^2_i,...>$ .</e^0_i,e^1_i,e^2_i,...></p><p>We define a prefix of the process history as $h^k_i=<e^0_i,e^1_i,... e^k_i="">$, define $s_i$ as the state of the process $p_i$, $s^k_i$ denotes the state of $p_i$ immediately before the k-th event.</e^0_i,e^1_i,...></p><p>The global history $H$ is the union of the individual process histories, $H=h_1 \cup h_2 \cup … \cup h_N$, a global state $S$ is represented by any set of individual process states.</p><p>A <em>Cut C</em> of the system’s execution is a <em>union of prefixes</em> of process histories, $ C=h_1^{c1} \cup h^{c2}_2 \cup … \cup h^{cn}_N$ </p><p>A meaningful global state is <em>represented by a consistent cut</em>:</p><ul><li>cut C contains all events up to $e^{ci}_i$</li><li>State $s_i$ of each process contained in global state $S$ corresponding to the Cut C is that$p_i$ immediately after the last event $e^{ci}_i$ has been processed.</li><li>The set of last events of the individual process prefixes is called frontier.</li><li>a cut is inconsistent if it shows an effect without cause.</li></ul><p>A Cut C is consistent if it also contains all events that happened-before for each of this cut’s event. $ \forall e \in C, f \rightarrow e \Rightarrow f \in C$ </p><p>一个切割把进程线上的事件分成两个部分，如果切割线不跨越通信线，那么是一个一致性切割，如果跨越了通信线，但两个切割事件没有因果关系，也不会导致切割的不一致，对于正在传送中的消息是一致但非强一致的状态。</p><h3 id="snapshot-algorithms"><a href="#snapshot-algorithms" class="headerlink" title="snapshot algorithms"></a>snapshot algorithms</h3><p>purpose:</p><ul><li>provide a potential consistent past global state</li><li>global predicates can only be evaluated by means of consistent snapshots</li><li>a predicate is stable if it continues to hold after it applied once</li><li>a potential past state is useful for the detection of stable predicates.</li></ul><p>Lai and Yang’s snapshot algorithm:</p><ol><li>initially, all nodes are black and send black messages.</li><li>The initiator becomes red and stores its local state</li><li>red nodes only send red messages</li><li>other nodes become red, if they receive an order to snapshot or a red message</li><li>before a node becomes red, it saves its local state and sends it to the initiator</li><li>if a red node receives a black message, it sends a copy of the message to the initiator.</li><li>The snapshot is complete if the initiator has received the local states of all nodes, and a copy of each black message that was on the way.</li></ol><p>让所有进程进入snapshot状态并记录当前的global state。首先initiator发送消息给其它进程，其它进程收到initiator的red message后开始记录自己 local state发送给initiator，然后变红。如果红点收到黑消息，就发送一份copy给initiator</p><p>Chandy and Lamport algorithm:</p><p>use flooding as basic wave procedure.</p><ul><li>A control message “pushes” the black messages to go to the FIFO channels</li><li>If a node receives a control message over a channel, then it knows it won’t receive more black message over that channel.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">Marker receiving rule for process pi</div><div class="line">Pi received a marker msg from channel c:</div><div class="line">if (pi has no yet recorded its state):</div><div class="line">it records its process state now</div><div class="line">it records the state of c as the empty set</div><div class="line">it runs on recording msg over other incoming channels</div><div class="line">else:</div><div class="line">pi stop record c&apos;s state and take the message it has recieved before as the state of c.</div><div class="line"></div><div class="line">Marker sending rule for process pi</div><div class="line">after pi has recorded its state, for each outgoing channel c:</div><div class="line">pi sends one marker message over c before it sends any other message over c</div></pre></td></tr></table></figure><p>进程1想知道全局状态，先向其他进程发起marker消息，并开始记录发送过marker消息的信道状态。</p><p>当进程从信道c第一次收到marker时，开始记录该信道状态，并向其它信道发送marker。</p><p>弱进程从信道c第二次收到marker，则停止记录该信道状态，并将已记录的消息座位该信道状态。</p><h2 id="Distributed-termination-detection"><a href="#Distributed-termination-detection" class="headerlink" title="Distributed termination detection"></a>Distributed termination detection</h2><p>Asynchronous model: process are active or passive, determine whether all processes are passive and no messages are on the way at the certain point of time.</p><p>Process model: determine whether all process are passive at a certain point in time, because message in this model have no delay.</p><p>Atom model: Actions are atomic and need no time, determine whether no messages are on the way at a certain point in time.</p><p>Simple counting algorithm: An observer visits each node and separately sums up the basic messages sent and received, when the number of sent messages and received messages are same, then it may terminate.</p><p>But: it is not sufficient for termination, because due to the cut, the message may be sent in the future received in the past.</p><p>Solution:</p><ol><li><p>freezing the system:</p><ul><li>no messages are sent in the frozen system</li><li>then sums up the messages, if both sums are equal, terminate</li><li>unfreezes system</li></ul><p>drawback: decrease concurrency</p></li><li><p>Double counting algorithm</p><ul><li>An observer twice visits all nodes, and determine the respective sums of messages received and sent</li><li>If 4 sums are equal, terminate</li></ul><p>if termination was not detected, second wave as first wave of the new round, re-entrant.</p></li><li><p>control topologies: different ways of waves for termination</p><ul><li>sequential waves: use a logical ring and two subsequent sequential ring circuits, $O(n)$</li><li>parallel waves: span tree and two subsequent accumulations each from leafs to root $O(log n)$</li><li>usage of echo algorithm</li></ul></li><li><p>time zone algorithm</p><p>An observer visits all nodes and builds a send and receive sum respectively</p><p>​</p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;• What is the problem with global snapshots?&lt;br&gt;• What is a global state?&lt;br&gt;• Which snapshot algorithms do you know?&lt;/p&gt;
&lt;p&gt;snapshot problem&lt;/p&gt;
&lt;p&gt;consistency criterion for consistent cuts&lt;/p&gt;
&lt;p&gt;snapshot algorithms&lt;/p&gt;
&lt;p&gt;snapshot applications&lt;/p&gt;
    
    </summary>
    
      <category term="notes" scheme="http://yoursite.com/categories/notes/"/>
    
    
      <category term="TUBcourse" scheme="http://yoursite.com/tags/TUBcourse/"/>
    
      <category term="Distributed Algorithm" scheme="http://yoursite.com/tags/Distributed-Algorithm/"/>
    
  </entry>
  
  <entry>
    <title>Distributed Algorithm C6 Clocks</title>
    <link href="http://yoursite.com/2017/03/05/DAlg-notes-C6/"/>
    <id>http://yoursite.com/2017/03/05/DAlg-notes-C6/</id>
    <published>2017-03-05T08:34:20.000Z</published>
    <updated>2017-03-08T08:40:41.000Z</updated>
    
    <content type="html"><![CDATA[<p>• Why do we need clocks in distributed systems?<br>• What’s the problem anyway, ever computer in the system has a clock…<br>• Synchronization of physical clocks, how do we realize this?<br>• What are Logical Clocks, and what kind of logical clocks do you know?</p><p>Time in Distributed Systems</p><p>Synchronization of physical clocks</p><ul><li>External clock synchronization after Cristian</li></ul><p>Order of events</p><p>Logical clocks</p><ul><li>Lamport clocks</li><li>vector clocks</li><li>application of vector clocks: causal broadcast</li></ul><a id="more"></a><h2 id="Time-in-Distributed-Systems"><a href="#Time-in-Distributed-Systems" class="headerlink" title="Time in Distributed Systems"></a>Time in Distributed Systems</h2><p>A clock maps the real time $t$ on a time stamp $C(t)$</p><p>Resolution: smallest period of time by which two values of the clock can differ.</p><p>Drift: Deviation of the speed of the clock from real time.</p><p>offset: Deviation of the clock from the real time at a point in time. i.e., $t-C(t)$</p><p>Each computer has its own inaccurate digital clock, the drifts are different from each other, without synchronization, the values of the clocks can differ arbitrarily from each other, thus we need <em>clock synchronization</em></p><h2 id="Synchronization-of-physical-clocks"><a href="#Synchronization-of-physical-clocks" class="headerlink" title="Synchronization of physical clocks"></a>Synchronization of physical clocks</h2><h3 id="Synchronization-interval"><a href="#Synchronization-interval" class="headerlink" title="Synchronization interval"></a>Synchronization interval</h3><p>Two correct clocks with drift $\rho$ should not deviate by more than $d$. </p><p>If the clocks are synchronized at $t=0$, then $C_1(t)=(1+\rho)t$  (faster) and $C_2(t)=t / (1+\rho)$ (slower) <strong>???为啥不是$1-\rho$ ???</strong></p><p>$(1+\rho)t - \frac{t}{1+\rho} \le d$ , the clock must be synchronized again before $d\frac{1+\rho}{2\rho + \rho^2}$ </p><p>If $\rho$ is very small, synchronization every $d/2\rho$ </p><h3 id="External-clock-synchronization-Cristian"><a href="#External-clock-synchronization-Cristian" class="headerlink" title="External clock synchronization (Cristian)"></a>External clock synchronization (Cristian)</h3><p>For known message delays $x$, if process $P_2$ wants to adjust its clock based on process $P_1$, it just need to use $P_1$ ‘s time $t_1$ of sending message, plus the message delay $x$, then subtract $P_2$ ‘s time $t_2$ when receives the message, after that we know how  much time we need to adjust $P_2$’s clock.</p><p>For unforeseeable message delay, the preceding procedure leas only to an approximate adjustment.</p><p>Requirements:</p><ul><li><p>great leaps of the clock time shall be avoided</p></li><li><p>the clock time must not decrease</p><p>The local clock runs slower or faster until the offset is compensated.</p></li></ul><p>Berkeley Algorithm: Assume clocks are correct, calculate the average of all clocks as the measure to adjustment.</p><h2 id="Order-of-Events"><a href="#Order-of-Events" class="headerlink" title="Order of Events"></a>Order of Events</h2><h3 id="definitions"><a href="#definitions" class="headerlink" title="definitions"></a>definitions</h3><p>Sending and receiving of a message are events. In distributed systems, the absolute point in time of events are often not important, we care about the order of events.</p><p>Partial order: the order relation is not defined for all pairs of events.</p><p>Total order: the order relation is defined for all pairs of events. i.e. $e_1 &lt; e_2 \rightarrow e_1 &lt; e_2 \vee e_2 &lt; e_1$</p><h3 id="possible-order-requirements"><a href="#possible-order-requirements" class="headerlink" title="possible order requirements"></a>possible order requirements</h3><ol><li><p>FIFO. If a process sends $m_1$ before $m_2$, then $m_1$ is delivered before $m_2$ to the receiver</p></li><li><p>casual order. A received message might cause the receiver to send another message, while another process may get these two messages in wrong order. </p><p>=&gt; we can keep causalities based on “happened before” relation.</p></li></ol><h3 id="“Happened-before”-Relation-Lamport"><a href="#“Happened-before”-Relation-Lamport" class="headerlink" title="“Happened before” Relation (Lamport)"></a>“Happened before” Relation (Lamport)</h3><p>Use the relation $\rightarrow$ to fulfill two following conditions:</p><ul><li>If $a$ and $b$ are two events in a process and $a$ occurs before $b$, then $a \rightarrow b$ （a是由b引起的）</li><li>If $a$ is the sending of a message in a process and $b$ is the receipt of the same message in another process, then $a \to b$.</li><li>If $a \to b$, an event $b \neq a$ <em>casually depends</em> on $a$.</li><li>If neither $a \to b$ nor $b \to a$ , written $a \parallel b$  , two events $a \neq b$  are <em>causally independent</em>, also called <em>concurrent</em>. （如果a和b没有因果关系，可以理解为他们是并发的）</li></ul><p>logical clock解决的是给分布式系统中所有时间定一个顺序，使这个顺序可以正确排列出有因果关系的事件，使得分布式系统在逻辑上不会发生因果倒置的错误。</p><p>We have several interpretations:</p><ul><li>$a \to b \Rightarrow$ $b$ casually depends on $a$</li><li>$a \parallel b \Rightarrow$ $a$ and $b$ have not influenced each other causally</li><li>$a \to b \Leftrightarrow$ as the time ascending, one can get from $a$ to $b$ in space-time diagram by following the process lines and message lines.</li></ul><p>Casual order: If the sending of message $m_2$ causally depends on sending the message $m_1$, then no receiver getting both messages delivers $m_2$ before $m_1$.</p><p>Total delivery order: If two processes $P$ and $Q$ both deliver the messages $m_1$ and $m_2$ , then $P$ delivers $m_1$ before $m_2$ only if $Q$ also does that.</p><p>Total FIFO order: both FIFO and total</p><p>Total causal order: both causal and total</p><h2 id="Logical-clocks"><a href="#Logical-clocks" class="headerlink" title="Logical clocks"></a>Logical clocks</h2><p>For each event $e$, assign a time stamp $C(e)$</p><p>Each process $P_i$ manages a counter $C_i$, when a event $e$ occurs, $C_i$ increases 1, the event gets the new value as <em>logical time stamp</em>.</p><p>$C(e)$ defines a partial order on the set of events, $e_1 &lt; e_2 \Leftrightarrow C(e_1)&lt;C(e_2)$ </p><p>The time stamp $C^ {‘} (e_i)$ of an event $e_i$ is a pair $(C_i, P_i)$, $e_1 &lt; e_2 \Leftrightarrow C^{‘}(e_1) &lt; C^{‘}(e_2) \Leftrightarrow C_1&lt;C_2 \vee C_1 =C_2 \wedge P_1 &lt; P_2$ </p><p>For two arbitrary events, $e1 \neq e_2 \Rightarrow e_1 &lt; e_2 \vee e_2 &lt; e_1$ </p><p><em>But the simple logical time does not consider the causal correlation between events.</em></p><h3 id="Clock-condition-Lamport"><a href="#Clock-condition-Lamport" class="headerlink" title="Clock condition (Lamport)"></a>Clock condition (Lamport)</h3><p>For all events $a, b$ , apply: $a \rightarrow b \Rightarrow C(a) &lt; C(b)$, so that the clock preserves the causal order of the events.</p><p>Only applies $C(a) &lt; C(b) \Rightarrow a \rightarrow b \vee a \parallel b$</p><p>also $C(a) = C(b) \Rightarrow a \parallel b$</p><p>$a \rightarrow b$ 可以推出$C(a) &lt; C(b)$， 但反过来不一定</p><p>Logical Clock解决的问题是找到一种方法，给分布式系统中所有时间定一个序，这个序能够正确地排列出具有因果关系的事件(不能保证并发事件的真实顺序)</p><p>The logical time stamps define a partial order on the set of events that maintains the causal connection between events.</p><p>Lamport’s Clocks Realization:</p><p>Each $P_i$ has a logical clock $L_i$, whose value is adapted at the occurrence of the following events:</p><ul><li>local event with process $P_i$: $L_i$ ++, the event gets new value as time stamp.</li><li>$P_i$ sends a message: $L_i$ ++, the send event gets new value as time stamp</li><li>$P_i$ receives a message: $L_i = max(L_i, t_m)+1$ (前续事件的时间戳与接受到的消息的时间戳中较大者+1)</li></ul><p>Problem: We can not be sure whether two events causally depend on each other only by a time stamp. </p><h3 id="Vector-clocks-Mattern-Fidge"><a href="#Vector-clocks-Mattern-Fidge" class="headerlink" title="Vector clocks(Mattern, Fidge)"></a>Vector clocks(Mattern, Fidge)</h3><p>Each process $P_i$ holds a vector time stamp $V_i$ consisting of n counters that are initially all zero.</p><ul><li>If an event occurs in a process $P_i$, the i-th component of its vector increases 1.</li><li>If $P_i$ sends a message, the new version of $V_i$ is sent along.</li><li>If $P_i$ receives a message with vector time stamp $T$, it forms the maximum of the new version of $V_i$ and $T$, <em>component-by-component</em>.(v1, v2两个向量，如果v1中的每个元素都不比其在v2中对应的元素小，那么v1&gt;v2；若两个向量中都有元素比对方向量的对应元素大，那么v1=v2；max(v1,v2)为两个向量的最大元素组成的向量)</li></ul><h3 id="Matrix-clocks"><a href="#Matrix-clocks" class="headerlink" title="Matrix clocks"></a>Matrix clocks</h3><p>Every process $P_i$ has a matrix time stamp $M_i$ given by a $n \times n$ -matrix initialized by zero matrix.</p><p>If a local event occurs, process $P_i$ increases the components $M_i[i,i]$ (the i-th element at diagonal) by 1.</p><p>Interpretation of the elements of matrix $M_i$:</p><ul><li>$M_i[i,i]$ is the local clock $P_i$</li><li>$M_i[i,l]$ is the knowledge of $P_i$ on the local clock of $P_l$</li><li>$M_i[k,l]$ is the knowledge of $P_i$ on the knowledge of $P_k$ on the local clock of $P_l$ </li></ul><p>If $P_j$ gets a message from $P_i$,</p><ul><li>update the time vector of $P_j$ with the time vector of $P_i$: what $P_j$ knows about the local clock of $P_k$</li><li>update the knowledge of $P_j$ on the time vector of other processes $P_k$: what $P_j$ knows about what $P_k$ knows on the local clock $P_i$.</li></ul><h2 id="Application-of-vector-and-matrix-clocks"><a href="#Application-of-vector-and-matrix-clocks" class="headerlink" title="Application of vector and matrix clocks"></a>Application of vector and matrix clocks</h2><h3 id="application-of-vector-clocks-Causal-broadcast"><a href="#application-of-vector-clocks-Causal-broadcast" class="headerlink" title="application of vector clocks: Causal broadcast"></a>application of vector clocks: Causal broadcast</h3><p>each message shall be sent to all processes, and should satisfy causality.</p><p>$P_i$ only increments $V_i[i]$ if it sends a message</p><p>Delivery condition: A message sent by $P_i$ is only delivered to $P_j$ when the time stamp $T$ fulfills the condition: $T[i] = V_j[i]+1 \wedge \forall k \neq i: T[k] \le V_j[k]$ </p><p>It is sufficient to increase $V_j[i]$ by 1 at delivery, don’t need to calculate the maximum.</p><p>一个进程会给其他进程发消息，对同一个进程如果发送了两个消息i和j，那么其他所有进程应该先接到j再接到i，如果某个进程在收到j之前收到了i，会直到收到j再接收i。</p><h3 id="application-of-lamport-clocks-Causal-multicast-and-causal-unicast"><a href="#application-of-lamport-clocks-Causal-multicast-and-causal-unicast" class="headerlink" title="application of lamport clocks: Causal multicast and causal unicast"></a>application of lamport clocks: Causal multicast and causal unicast</h3><p>Lamport clock alone are not sufficient for implementing a causal multicast.</p><p>We can make processes send messages periodically or request messages on demand to ensure FIFO channels.</p><p>But this solution delays delivery.</p><p>It can also be used for causal unicast, but the delivery of messages can be unnecessarily delayed.</p><p>=&gt; matrix clocks for causal unicast.</p><h3 id="Application-of-matrix-clocks-Causal-unicast"><a href="#Application-of-matrix-clocks-Causal-unicast" class="headerlink" title="Application of matrix clocks: Causal unicast"></a>Application of matrix clocks: Causal unicast</h3><p>Every process $P_i$ has a matrix time stamp $M_i$ given by a $n \times n$ -matrix initialized by zero matrix.</p><p>If $P_i$ sends a message to $P_j$, $M_i[i,j]$ is incremented, and the new version of matrix $M_i$ is sent together with the message.</p><p>If $P_j$ gets a message, it calculates the component-wise maximum of its own matrix $M_j$ and the matrix $M$ contained in the message. $1 \le i, k\le n: M_j[i,k] = max(M_j[i,k], M[i,k])$ </p><p>在进程$P_i$给$P<em>j$发送信息时，$P</em>{ii}$ 加1，无论是$P_j$ 知道的$P_i$ 已发给$P_j$ 的消息数，还是其他进程认为的$P_j$已知的$P_i$发给$P<em>j$ 的消息数都不能大于$P</em>{ii}$</p><p>Delivered condition:</p><ul><li>$M[i,j]=M_j[i,j]+1$ to make sure the message is the next message that $P_j$ expects from $P_i$</li><li>$ \forall k \neq i, 1 \le k \le n: M[k,j] \le M_j[k,j]$ </li></ul><p>The maximum of $M$ and $M_j$ is calculated after delivery of the message</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;• Why do we need clocks in distributed systems?&lt;br&gt;• What’s the problem anyway, ever computer in the system has a clock…&lt;br&gt;• Synchronization of physical clocks, how do we realize this?&lt;br&gt;• What are Logical Clocks, and what kind of logical clocks do you know?&lt;/p&gt;
&lt;p&gt;Time in Distributed Systems&lt;/p&gt;
&lt;p&gt;Synchronization of physical clocks&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;External clock synchronization after Cristian&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Order of events&lt;/p&gt;
&lt;p&gt;Logical clocks&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Lamport clocks&lt;/li&gt;
&lt;li&gt;vector clocks&lt;/li&gt;
&lt;li&gt;application of vector clocks: causal broadcast&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="notes" scheme="http://yoursite.com/categories/notes/"/>
    
    
      <category term="TUBcourse" scheme="http://yoursite.com/tags/TUBcourse/"/>
    
      <category term="Distributed Algorithm" scheme="http://yoursite.com/tags/Distributed-Algorithm/"/>
    
  </entry>
  
  <entry>
    <title>Distributed Algorithms C5 Mutual Exclusion</title>
    <link href="http://yoursite.com/2017/03/04/DAlg-notes-C5/"/>
    <id>http://yoursite.com/2017/03/04/DAlg-notes-C5/</id>
    <published>2017-03-04T08:34:15.000Z</published>
    <updated>2017-03-08T08:39:46.000Z</updated>
    
    <content type="html"><![CDATA[<p>• We discussed several types of algorithms for mutual exclusion, can you tell me which?<br>• What are the two main requirements for mutual exclusion algorithms?<br>• There is often another requirement needed, which is…?<br>• Explain the … algorithm.</p><p>problem of mutual exclusion</p><p>Algorithm with central coordinator</p><p>Broadcast-based algorithms</p><p>Quorum-based algorithms</p><p>Token-based algorithms</p><p>Comparison of algorithms</p><a id="more"></a><h2 id="Mutual-exclusion"><a href="#Mutual-exclusion" class="headerlink" title="Mutual exclusion"></a>Mutual exclusion</h2><p>Coordination of the exclusive access on resources, often, there’s only 1 process shall access the resource</p><p>If a process has the right to access, he releases it after finite time voluntarily.</p><h3 id="Requirements"><a href="#Requirements" class="headerlink" title="Requirements"></a>Requirements</h3><ul><li><p>safety: something bad that cannot be undone shall never happen, 不该发生的绝不发生</p></li><li><p>liveness: something that should happen eventually happens，该发生的确保发生</p></li><li><p>fairness: No starvation, if a process wants access, the access has to be allowed after finite time.</p><p>strong fairness: The allowance of access takes the order of access requests into account</p></li><li><p>often a trivial solution is possible for only one of the safety and liveness.</p></li></ul><h2 id="Algorithm-with-Central-Coordinator"><a href="#Algorithm-with-Central-Coordinator" class="headerlink" title="Algorithm with Central Coordinator"></a>Algorithm with Central Coordinator</h2><p>A process is assigned as <em>coordinator</em>.</p><p>Coordinator grants accesses, 3 messages per access with blocking operations.</p><p>e.g: suppose processes 1, 2, 3 and a coordinator k. If process 1 wants to access, it should ask k if the resource is free, if k answers free, it gets access and send a message to tell k it has done the job.</p><p>Disadvantages:</p><ul><li>Single point of failure</li><li>Asymmetrical load distribution</li></ul><h2 id="Broadcast-Based-Algorithms-Lamport"><a href="#Broadcast-Based-Algorithms-Lamport" class="headerlink" title="Broadcast-Based Algorithms (Lamport)"></a>Broadcast-Based Algorithms (Lamport)</h2><p>Assume that all messages have an unique <em>logical time stamps</em>, lossless FIFO-communication channels.</p><h3 id="Basic-idea"><a href="#Basic-idea" class="headerlink" title="Basic idea:"></a>Basic idea:</h3><ul><li>Each process manages a message queue ordered according to time stamps.</li><li>Requests and releases are sent to all processes via broadcast.</li></ul><p>a process must only access if:</p><ul><li>its own request is the first request in its own queue</li><li>It already received a message (request 和 confirmation都可以) from each other process with a larger time stamp</li></ul><h3 id="Broadcast-Algorithm"><a href="#Broadcast-Algorithm" class="headerlink" title="Broadcast Algorithm:"></a>Broadcast Algorithm:</h3><p>每个进程维护一个队列，请求开始时，先将请求插入自身队列，发送request给其他进程，其他进程将请求插入自己的队列，再回确认消息，执行任务后发送释放资源的消息给其他进程，再将这个请求移出队列。</p><ol><li>Issue access request: insert request into own queue, send it to all other processes</li><li>Receive access request: insert request into its own queue according to the order of time stamp, send request confirmation to requesting process.</li><li>Send release after access: remove own request from own queue, send release to all other processes.</li><li>Received release: remove request from own queue.</li></ol><p>message complexity: sending $n-1$ requests, $n-1$ processes send their confirmation, sending of release to $n-1$ processes. Thus, $3(n-1)$ messages per access altogether.</p><h3 id="Improvement-by-Ricart-and-Agrawala"><a href="#Improvement-by-Ricart-and-Agrawala" class="headerlink" title="Improvement (by Ricart and Agrawala):"></a>Improvement (by Ricart and Agrawala):</h3><p>Idea: avoid explicit release messages through delayed confirmation. (不要release的消息，用delayed confirmation代替，以至每个access只需要$2(n-1)$条消息)</p><p>Issue access request: For a new request, give a sequence number to this request, this number is by 1 larger than all previously received requests, then send request to all other $n-1$ processes, after receive $n-1$ confirmations, access.</p><p>When a request arrives: if not applied or the sender has “older rights”, send confirmation immediately, other wise, confirmation is sent only after the ending of the own access.</p><p>一个进程想访问资源，它发送一个消息包含request，进程号和序列号（从1开始，大于该进程之前收到的请求）给其它进程告诉大家它要访问资源。对于接收者，如果它已获得对资源的访问，它就不进行应答，直到完成它的访问再发送delayed confirmation给发送者；如果是接收者想访问资源但还没开始，它会比较自身请求的序列号和它收到的请求的序列号，序列号小的胜出（序列号也可以是时间戳）；如果接收者没有访问资源也不打算访问，就发一个immediate confirmation给发送者。</p><h3 id="Requirements-1"><a href="#Requirements-1" class="headerlink" title="Requirements:"></a>Requirements:</h3><p>a solution that requires less message per access and still distributes the load equally between all processes.</p><p>a solution which does not include the involvement of all process in each coordination and still distributes the load equally between all processes.</p><h2 id="Quorum-Based-Algorithms"><a href="#Quorum-Based-Algorithms" class="headerlink" title="Quorum Based Algorithms"></a>Quorum Based Algorithms</h2><h3 id="Process-mesh-algorithm-Maekawa"><a href="#Process-mesh-algorithm-Maekawa" class="headerlink" title="Process mesh-algorithm (Maekawa)"></a>Process mesh-algorithm (Maekawa)</h3><p>基于子集请求而不是全集请求的互斥算法</p><p>$n$ processes are arranged in a quadratic mesh with an edge length of $\sqrt{n}$</p><p>A process $P_i$ must ask its granting set $R_i$ for allowance before access. For all pairs of process $P_i$ and $P_j$, their $R_i$ and $R_j$ have at least two processes in common. Granting sets have the cardinal number $2\sqrt{n}-2$, namely $R_i - P_i$ </p><p>Message complexity:</p><ul><li><p>send request to $2\sqrt{n}-2$ processes</p></li><li><p>$2\sqrt{n}-2$ processes send confirmation</p></li><li><p>send release to  $2\sqrt{n}-2$ processes</p><p>==&gt; $3[2\sqrt{n}-2]$ messages per access altogether.</p></li></ul><p>Problem: deadlocks may occur. </p><ol><li>introduce two additional message types to avoid deadlocks.</li><li>increase the number of messages per access on $5[2\sqrt{n}-2]$ in the worst-case.</li></ol><p>Another arrangement involving smaller cardinal number of the granting set?</p><p>=&gt; triangular arrangement</p><p>Use triangular arrangement, a single common process would be enough, with granting set size about $\sqrt{2}\sqrt{n}$ .</p><p>Problem: some processes may need more confirmation.</p><p><strong>???solution for load balancing???</strong></p><p>used for 2 different schemes</p><p>The first is nodes on same column and the one on the top left, the second is nodes on same row and the one down on the right side.</p><p>For the same scheme, granting set intersects with each other.</p><p>Also, granting set can intersect with granting set of other schemes.</p><p>All processes occur altogether in both schemes equally often in a granting set.</p><p>=&gt; <em>Thus, use both schemes randomly can attain load balancing.</em></p><h3 id="Minimal-Arrangement"><a href="#Minimal-Arrangement" class="headerlink" title="Minimal Arrangement"></a>Minimal Arrangement</h3><p>Suppose $K$ is the size of the granting set, then a minimal arrangement exists if $K-1=p^m$, $p$ is a prime number, $n$ is a natural number, then the arrangement has $n=K(K-1)+1$ processes.</p><h2 id="Token-Based-Algorithms"><a href="#Token-Based-Algorithms" class="headerlink" title="Token Based Algorithms"></a>Token Based Algorithms</h2><h3 id="Simple-token-Ring-solution-Le-Lann"><a href="#Simple-token-Ring-solution-Le-Lann" class="headerlink" title="Simple token Ring-solution (Le Lann)"></a>Simple token Ring-solution (Le Lann)</h3><ul><li>Processes are arranged in a logical ring</li><li>Access is controlled by circulation token</li><li>Applicants waits for access until token reaches it</li><li>Accessing process relays the token with the release</li><li>Process without access intention relays the token directly</li><li>possible to use separate tokens for coordinating access to individual resources</li></ul><p>进程0得到token后沿着环进行传递，进程获得令牌时，如果有访问需求，就对资源进行访问，完成后继续向后传递token，如果没有则直接传token给后继。</p><p>advantages: simple, correct, fair, no deadlocks, no starvation.</p><p>Disadvantages: token is always on the way, sometimes it’s useless. The message number per request is not limited. Need to wait for a long time if there’re large number of processes.</p><h3 id="Token-based-solution-Suzuki-and-Kasami"><a href="#Token-based-solution-Suzuki-and-Kasami" class="headerlink" title="Token-based solution (Suzuki and Kasami)???"></a>Token-based solution (Suzuki and Kasami)???</h3><p>A requesting process sends a request with its sequence number to all other processes (ring circuit or via broadcast)</p><p>Each process $P_i$ stores the highest currently received sequence number in a list $R_i$.</p><h3 id="Lift-Algorithm-Raymond"><a href="#Lift-Algorithm-Raymond" class="headerlink" title="Lift Algorithm (Raymond)"></a>Lift Algorithm (Raymond)</h3><p>Use a spanning tree for selective relay (转发) of the request in direction to the token.</p><p>The edges have two directions.</p><p>The token wanders against the arrow direction, every time the token passed an edge, it changes the direction of this edge.</p><p>A process that wants the token sends request over its outgoing edge.</p><p>request顺着箭头方向发，token逆着箭头方向发，token经过一条边这条边的方向会被改变。</p><p>每个process记录给它发送request的process</p><p>If a process receives the token, it can send it in one of the requesting directions, or if there are more requests from other directions, it sends a request after the token.</p><p>$O(log_kn)$ messages per access are needed, $k$ is the k-ray.</p><blockquote><p>a k-ary tree is a rooted tree in which each node has no more than k children</p></blockquote><p>Start state: winner of an election gets the token and creates a spanning tree with edges directed towards itself.</p><h2 id="Comparison-of-message-complexity-per-access"><a href="#Comparison-of-message-complexity-per-access" class="headerlink" title="Comparison of message complexity per access"></a>Comparison of message complexity per access</h2><table><thead><tr><th>procedure</th><th>message complexity</th></tr></thead><tbody><tr><td>Token Ring</td><td></td></tr><tr><td>Simple broadcast</td><td></td></tr><tr><td>Improved broadcast</td><td></td></tr><tr><td>improved token ring</td><td></td></tr><tr><td>mesh arrangement</td><td></td></tr><tr><td>lift algorithm on k-ary tree</td><td></td></tr><tr><td>central manager</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;• We discussed several types of algorithms for mutual exclusion, can you tell me which?&lt;br&gt;• What are the two main requirements for mutual exclusion algorithms?&lt;br&gt;• There is often another requirement needed, which is…?&lt;br&gt;• Explain the … algorithm.&lt;/p&gt;
&lt;p&gt;problem of mutual exclusion&lt;/p&gt;
&lt;p&gt;Algorithm with central coordinator&lt;/p&gt;
&lt;p&gt;Broadcast-based algorithms&lt;/p&gt;
&lt;p&gt;Quorum-based algorithms&lt;/p&gt;
&lt;p&gt;Token-based algorithms&lt;/p&gt;
&lt;p&gt;Comparison of algorithms&lt;/p&gt;
    
    </summary>
    
      <category term="notes" scheme="http://yoursite.com/categories/notes/"/>
    
    
      <category term="TUBcourse" scheme="http://yoursite.com/tags/TUBcourse/"/>
    
      <category term="Distributed Algorithm" scheme="http://yoursite.com/tags/Distributed-Algorithm/"/>
    
  </entry>
  
  <entry>
    <title>Distributed Algorithm C4 -- Election Algorithms</title>
    <link href="http://yoursite.com/2017/03/03/DAlg-notes-C4/"/>
    <id>http://yoursite.com/2017/03/03/DAlg-notes-C4/</id>
    <published>2017-03-03T08:34:12.000Z</published>
    <updated>2017-03-08T08:38:58.000Z</updated>
    
    <content type="html"><![CDATA[<p>• Why do we need election algorithms?<br>• Which election algorithms do you know?<br>• Explain the … algorithm.<br>• What are the drawbacks of this algorithm and can it be improved?<br>• What is the message complexity of this algorithm.</p><p>Election algorithms for</p><ul><li>arbitrary connected topologies</li><li>unidirectional and bidirectional rings</li><li>trees</li></ul><p>Randomized election algorithms for</p><ul><li>bidirectional rings</li><li>anonymous rings</li></ul><a id="more"></a><h2 id="The-election-problem"><a href="#The-election-problem" class="headerlink" title="The election problem"></a>The election problem</h2><p>Select a <em>unique</em> leader from a set of identical processes, assume that each node has a unique integer identity &gt; 0.</p><p>It requires each node shall know the winner in the end, also everyone can initiate the algorithm. For example, determine the largest identity in the topology can be used as election algorithm.</p><h2 id="Election-for-arbitrary-topologies"><a href="#Election-for-arbitrary-topologies" class="headerlink" title="Election for arbitrary topologies"></a>Election for arbitrary topologies</h2><p>We suppose that each process has a unique identity $p$ and a local variable $M_p$ , which is 0 initially.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">Ip: &#123;Mp == 0&#125;</div><div class="line">Mp = p</div><div class="line">SEND &lt;Mp&gt; TO all neighbors</div><div class="line">Rp: &#123;A message &lt;j&gt; has arrived&#125;</div><div class="line">IF Mp &lt; j, THEN:</div><div class="line">Mp = j;  </div><div class="line">SEND &lt;Mp&gt; to all other neighbors</div><div class="line">Tp: &#123;termination was discovered&#125;</div><div class="line">IF Mp == p, THEN:</div><div class="line">&quot;I am the master&quot;</div><div class="line">ELSE:</div><div class="line">&quot;Mp is the master&quot;</div><div class="line">FI</div></pre></td></tr></table></figure><p><strong>???Mp = p for every node, or each node initiates this algorithm at the same time???</strong></p><h3 id="Echo-election-algorithm"><a href="#Echo-election-algorithm" class="headerlink" title="Echo election algorithm"></a>Echo election algorithm</h3><p>Echo election algorithm is suitable for arbitrary connected topologies. </p><p>Each initiators starts an instance of this algorithm, the explorer and echo carry the identity of the initiators, weaker messages are not passed (message extinction), strongest wave prevails and terminates at the winner, so the winner know it has won. If a initiator receives a stronger message, it knows that it has lost the election, stronger initiators will not send echo for it.</p><p>The winner starts the echo algorithm again to tell other it has won, and other waves finally stagnate somewhere.</p><h3 id="Election-Algorithms-for-unidirectional-Rings"><a href="#Election-Algorithms-for-unidirectional-Rings" class="headerlink" title="Election Algorithms for unidirectional Rings"></a>Election Algorithms for unidirectional Rings</h3><h4 id="Bully-algorithm"><a href="#Bully-algorithm" class="headerlink" title="Bully- algorithm"></a>Bully- algorithm</h4><p>Each process wakes up as an initiator or receives a message from its neighbor. </p><p>Each waking up starts a complete ring circulation.</p><p>Finally, each node receives a message with its own identity and the largest node’s ID.</p><p>If both IDs are same, namely in the final message of each nodes $<i, j="">$, $i = j$, then the node is the master, otherwise it has lost.</i,></p><p>For every circulation of each process:</p><ol><li><p>Each node holds its identity value $p$. The initiator sends a message like $<i, j="">$ to its next node, $i$ is its identity value, $j$ is the highest value currently.</i,></p></li><li><p>When a node receives a message:</p><p>firstly it compares $i$ and its $p$ to check if a cycle of message exchange has finished. </p><ul><li>If not, then it compares the current highest value in the message $j$ to its identity value $p$, find the largest between $j$ and $p$, $k = max(j, p)$, and send message $<i, k="">$ to the next node.</i,></li><li>Else, this node compares the current highest value in the message $j$ to its own value $p$, if they are equal, then this node is the master, else, the node hold the value $j$ is the master.</li></ul></li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">Ip: &#123;init == FALSE&#125;</div><div class="line">init = TRUE;</div><div class="line">SEND &lt;p, p&gt; TO next node.</div><div class="line">    # the first p is the sender ID, and the second p is highest ID known</div><div class="line">Rp: &#123;A message &lt;i, j&gt; has arrived&#125;</div><div class="line">IF i != p, THEN:</div><div class="line">k = max(j, p);</div><div class="line">SEND &lt;i, k&gt; TO next node;</div><div class="line">ELSE:</div><div class="line">IF p == j, THEN:</div><div class="line">&apos;I am the master&apos;</div><div class="line">ELSE:</div><div class="line">&apos;j is the master&apos;</div><div class="line">FI</div><div class="line">FI</div></pre></td></tr></table></figure><h5 id="complexity"><a href="#complexity" class="headerlink" title="complexity"></a>complexity</h5><p>We need $n$ complete circulations.</p><p>$n^2$ single messages totally. The message complexity is $O(n^2)$.</p><h5 id="drawbacks-and-improvements"><a href="#drawbacks-and-improvements" class="headerlink" title="drawbacks and improvements"></a>drawbacks and improvements</h5><p>Only winners know it has won, we can add an extra round to inform all other nodes.</p><p>In this method, messages cannot lead to a win are passed on.</p><p>=&gt; We can use message extinction to fix these two problems.</p><h4 id="message-extinction-Chang-and-Roberts"><a href="#message-extinction-Chang-and-Roberts" class="headerlink" title="message extinction (Chang and Roberts)"></a>message extinction (Chang and Roberts)</h4><p>every node initiates a ring circuit, send its value to the next node, if its value larger than the next node’s, pass the value to the next after that, else this message will be swallowed. If a node can receive a message includes a value equal to its own value, that means this node is the master.</p><h5 id="features"><a href="#features" class="headerlink" title="features"></a>features</h5><ul><li>messages are only passed on if they can lead to a win, all other messages are extinct</li><li>only the winner receives its own message, use an additional ring circulation to inform other nodes that it won.</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">Ip: &#123;Mp == 0&#125;</div><div class="line">Mp = p;</div><div class="line">SEND &lt;Mp&gt; TO next node;</div><div class="line">Rp: &#123;message &lt;j&gt; has arrived&#125;</div><div class="line">IF Mp &lt; j, THEN:</div><div class="line">Mp = j;</div><div class="line">SEND &lt;Mp&gt; TO next node;</div><div class="line">FI</div><div class="line">IF j == p, THEN:</div><div class="line">&apos;I am the master&apos;</div><div class="line">&lt;inform others by another ring circuit&gt;</div><div class="line">FI</div></pre></td></tr></table></figure><h5 id="Message-complexity"><a href="#Message-complexity" class="headerlink" title="Message complexity"></a>Message complexity</h5><ol><li><p>worst case message complexity with k initiators happens when initiators are arranged on the ring in descending order and initiate election in ascending order. (消息传递的方向与节点值增大的方向相反)</p><p>suppose we have n nodes:</p><p>​            k-largest initiator, $n-(k-1)$ messages;</p><p>​            …</p><p>​            2nd largest initiator, $n-1$ messages;</p><p>​            1st largest initiator, $n$ messages;</p><p>​    Thus, the message volume with k initiators in worst case is:</p><p>​          $ n + (n-1) + (n-2) + (n-3) + … + (n-(k-1))$</p><p>​$= \frac{n(n+1)}{2} - \frac{(n-k)(n-k+1)}{2} $</p><p>​$= nk - \frac{k(k-1)}{2}$</p><p>​==&gt; $O(n^2)$ with ring size $n$ and $k=n$  plus $n$ additional messages for win notification</p></li></ol><ol><li>for the best case, if the initiators are arranged on the ring in ascending order and initiate the election approximately simultaneously, except the largest initiator need $n$ messages, others only need 1 message. Thus the message volume is $ n+k-1$ plus $n$ additional messages. The message complexity is $O(n)$.</li><li>Average case. For i-largest initiator, needs $n/i$ messages on average. So the average-case message complexity is $nH_k \approx n lnk$ , with $H_k = 1+1/2+…+1/k$ , still need $n$ messages for winner notification.</li></ol><h5 id="Influence-of-message-overtaking"><a href="#Influence-of-message-overtaking" class="headerlink" title="Influence of message overtaking"></a>Influence of message overtaking</h5><h2 id="Election-algorithms-for-Bidirectional-rings"><a href="#Election-algorithms-for-Bidirectional-rings" class="headerlink" title="Election algorithms for Bidirectional rings"></a>Election algorithms for Bidirectional rings</h2><h3 id="Hirschberg-Sinclair-Election-Algorithm"><a href="#Hirschberg-Sinclair-Election-Algorithm" class="headerlink" title="Hirschberg-Sinclair-Election Algorithm"></a>Hirschberg-Sinclair-Election Algorithm</h3><p>In this algorithm, each node try to compare its value to its right $2^{i-1}​$ neighbors and left $2^{i-1}​$ neighbors ($i = 1,2,3…​$, left and right neighbors totally $2^i​$) on a bidirectional ring until message arrives again at the node; node survived if it is larger than both two sides neighbors, and it receives an OK if it is larger than one neighbor, if node receive 2 OK in one phase, then it survived, else its state turns to passive from active.</p><h4 id="worst-case-message-complexity"><a href="#worst-case-message-complexity" class="headerlink" title="worst case message complexity"></a>worst case message complexity</h4><p>Suppose we have n nodes in a ring:</p><p>​    After phase 1, 1 passive process between active processes, max. $\frac{n}{2}$ nodes survive</p><p>​    After phase 2, 2 passive between active, max. $\frac{n}{3}$ survive</p><p>​    After phase 3, 4 passive between active, max. $\frac{n}{5}$ survive</p><p>=&gt; there will be $2^{i-1}$ passive processes between active processes after phase $i$, max. $\frac{n}{1+2^{i-1}}$  nodes survive.</p><p>=&gt;<strong>??? $\frac{n}{1+2^{i-1}}$ processes(nodes) can initiate chains with the length $2i$ </strong></p><p>Each chain with the length $2i$ generates at most $4*2i$ messages</p><p>in phase i, there are max $\frac{4 \times 2^i \times n}{1+2{i-1}} = \frac{2^{i-1} \ times 8n}{1+2^{i-1}} &lt; 8n$ messages.</p><p>There are maximal $1+log2n$ phases, thus at the most $8n + 8nlog2n$ messages, which has the time complexity $O(nlogn)$, also need $n$ messages for win notification.</p><p><strong>???time complexity $4n-2$ for $n=2k$ (worst case) and $6n-6$ for $n=2k+1$ (best case)???</strong></p><h4 id="drawbacks-and-improvements-1"><a href="#drawbacks-and-improvements-1" class="headerlink" title="drawbacks and improvements"></a>drawbacks and improvements</h4><p>Drawback: The initiator do not have to proceed the phases synchronously, thus an initiator which is already in a high phase can still stopped by a new larger initiator.</p><p>Improvement: pairs are used and ordered lexicographically rather than by node identities only.</p><ul><li>an initiator in a higher phase always prevails against an initiator in a lower phase, only if the phase is the same the node identity can be a tie breaker.</li><li>the algorithm is no longer a MAX-algorithm, it does not necessarily determine the node with the highest id as the winner.</li></ul><h3 id="Peterson-Election-Algorithm"><a href="#Peterson-Election-Algorithm" class="headerlink" title="Peterson Election Algorithm"></a>Peterson Election Algorithm</h3><p>和HS算法的区别在哪？？？？</p><p>In the beginning, all processes are active.</p><p>For each phase:</p><ul><li>Each active process communicates its IDs to the next active process in both directions.</li><li>Process receives higher ID become passive and only pass messages on</li><li>Only active processes participate in the next phase</li></ul><p>A node wins when it receives its own ID.</p><p>Additionally, a circulation for the win notification with $n$ messages.</p><h4 id="worst-case-message-complexity-1"><a href="#worst-case-message-complexity-1" class="headerlink" title="worst-case message complexity"></a>worst-case message complexity</h4><p>If a node survives, its neighbors do not survive.</p><p>In each phase, the number of active processes is at least halved, which means there are maximal $log_2n + 1$ phases.</p><p>Each node sends at most $2$ messages per phase, so $2n$  messages per phase at most.</p><p>=&gt; Worst case message complexity: $2n(log_2n +1)$</p><h4 id="Best-case-message-complexity"><a href="#Best-case-message-complexity" class="headerlink" title="Best-case message complexity"></a>Best-case message complexity</h4><p>If each node has one neighbor whose ID is higher than its ID in the first phase, then there is at most 2 phases to terminate the algorithm with $2n$ messages each.</p><p>=&gt; At most $4n$ messages. </p><blockquote><p>????The message sent from the largest to the smallest node circulates the ring -&gt; n messages</p><p>????all other messages go only to their respective neighbor -&gt; 2n-1 messages</p><p>????The algorithm terminates after only one phase, msg complexity is $3n-1$</p></blockquote><h4 id="Average-case-message-complexity"><a href="#Average-case-message-complexity" class="headerlink" title="Average-case message complexity"></a>Average-case message complexity</h4><p>First, arrange all nodes from largest to smallest. Then for each node, calculate the probability of it is smaller than the left neighbor and right neighbor, multiply these two probability value to get the probability this node is smaller than its two neighbors. Next, calculate the mean value of these probability that a node is smaller than both-side neighbors.</p><p>=&gt; A node survives a phase with the probability 1/3, and  $(log_3n+1)$ phases on average.</p><p>=&gt; Average-case is $2n(log_3n +1)$</p><h3 id="Unidirectional-Peterson-Election"><a href="#Unidirectional-Peterson-Election" class="headerlink" title="Unidirectional Peterson Election???"></a>Unidirectional Peterson Election???</h3><p>An active node compares its value with the value of the next active predecessor and the value of the next active successor. If it has the largest ID, it remains active, otherwise it becomes passive. 往一个方向的后继的两个节点发送当前节点的id</p><p>But on unidirectional rings messages can only be sent forward.</p><p>Solution: </p><ul><li>The IDs of the active predecessor and the current node are transmitted to the active successor, stored in the variables $v$ and $p$.</li><li>The comparison of the values with the own IDs is carried out by the successor.</li><li>If $v&gt;max(p,s)$ , it remains active and joins the next phase. (从左到右三个节点，分别有值p, v, s， 如果v比p和s都大，那么这个节点存活并进入下一阶段 )</li></ul><h2 id="Election-Algorithms-on-Trees"><a href="#Election-Algorithms-on-Trees" class="headerlink" title="Election Algorithms on Trees"></a>Election Algorithms on Trees</h2><h3 id="Three-phases"><a href="#Three-phases" class="headerlink" title="Three phases:"></a>Three phases:</h3><ol><li>Explosion phase: Election request is propagated to the leafs.<ul><li>The explosion starts at several initiators</li><li>If a node receives a explosion message for the first time, it will pass it on to all other neighbors</li><li>The explosion waves unite when explosion messages meets on the same edge</li></ul></li><li>Contraction phase: from the leafs the maximum of the already collected identities is propagated to the center.<ul><li>If a leaf node receives a explosion message, it will answer with its own identity immediately</li><li>If it is not a leaf node, it will compare the identities it received and its own identity, and send the max one over the last remaining edge.</li><li>In the end, two different max identity will meet on the same edge, both received nodes know the real maximum afterwards</li></ul></li><li>Information phase: Distribution of the real maximum from the center to all nodes in the network.<ul><li>from both nodes the maximum is flooded into the network, the edge between them is omitted.</li></ul></li></ol><h3 id="message-complexity-with-k-initiators"><a href="#message-complexity-with-k-initiators" class="headerlink" title="message complexity with k initiators"></a>message complexity with k initiators</h3><p>We assume that there are $n$ edges and $k$ initiators.</p><ul><li>explosion phase: one message over each edge, except 2 messages over $k-1$ <strong>meeting edges(???)</strong>, so the number of messages in this phase is $n-2+k$.</li><li>contraction phase: one message over each edge, two messages over the central edge, in total $ (n-1)-1=n-2$ messages.</li><li>information phase: one message over each edge, but no message over the central edge, totally $n$ messages.</li></ul><p>Altogether $3n + k -4$ messages.</p><p>Obviously, Election on trees is more efficient that Election on rings.</p><h2 id="Randomized-Election-Algorithms"><a href="#Randomized-Election-Algorithms" class="headerlink" title="Randomized Election Algorithms"></a>Randomized Election Algorithms</h2><p>Randomized algorithms are often more simple than deterministic algorithms that solve the same problem. Some problems can be solved more efficiently via randomized algorithms.</p><p>There are two categories of randomized algorithms, respectively <em>Las Vegas-Algorithms</em> and <em>Monte Carlo-algorithms</em>. For Las Vegas-algorithms, they are weakening of the termination, provide correct result, but the worst-case time complexity is unlimited. While Monte Carlo-algorithms are weakening partial correctness, but the worst-case run time is limited. </p><p>(Las Vegas算法保证准确性但时间复杂度高，Monte Carlo算法保证效率但可能会出错)</p><h3 id="Randomized-Election-in-Bidirectional-Rings"><a href="#Randomized-Election-in-Bidirectional-Rings" class="headerlink" title="Randomized Election in Bidirectional Rings"></a>Randomized Election in Bidirectional Rings</h3><p>Here, the average-case message complexity for $k=n$ is about $0.71n ln \ n$ . About 30% better than deterministic algorithm for unidirectional rings by Chang and Roberts.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;• Why do we need election algorithms?&lt;br&gt;• Which election algorithms do you know?&lt;br&gt;• Explain the … algorithm.&lt;br&gt;• What are the drawbacks of this algorithm and can it be improved?&lt;br&gt;• What is the message complexity of this algorithm.&lt;/p&gt;
&lt;p&gt;Election algorithms for&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;arbitrary connected topologies&lt;/li&gt;
&lt;li&gt;unidirectional and bidirectional rings&lt;/li&gt;
&lt;li&gt;trees&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Randomized election algorithms for&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;bidirectional rings&lt;/li&gt;
&lt;li&gt;anonymous rings&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="notes" scheme="http://yoursite.com/categories/notes/"/>
    
    
      <category term="TUBcourse" scheme="http://yoursite.com/tags/TUBcourse/"/>
    
      <category term="Distributed Algorithm" scheme="http://yoursite.com/tags/Distributed-Algorithm/"/>
    
  </entry>
  
  <entry>
    <title>Distributed Algorithm C3 -- Flooding, Broadcast and Echo</title>
    <link href="http://yoursite.com/2017/03/02/DAlg-notes-C3/"/>
    <id>http://yoursite.com/2017/03/02/DAlg-notes-C3/</id>
    <published>2017-03-02T08:33:11.000Z</published>
    <updated>2017-03-08T08:37:36.000Z</updated>
    
    <content type="html"><![CDATA[<ul><li>Explain the Echo/Broadcast/Flooding algorithm.</li><li>What are the differences?</li><li>What is the message complexity?</li></ul><p>Overview:</p><p>Flooding:distribute info, with/without confirmation, all nodes and edges</p><p>Echo:distribute info, all nodes and edges, selective confirmation, collect info, spanning tree</p><p>Broadcast:distribute, all nodes, without acknowledgement with special topologies</p><p>Multicast: distribute, specific group, with/without acknowledgement</p><a id="more"></a><h2 id="Flooding"><a href="#Flooding" class="headerlink" title="Flooding"></a>Flooding</h2><p>Precondition: connected topology.</p><p>Principle: <strong>Each node tells a new rumor that it got from one of its neighbors to all other neighbors, until all nodes are informed, already known rumors are ignored.</strong></p><p>Initially, <code>informed == FALSE</code> for all processes.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">I:  informed == FALSE</div><div class="line">    SEND &lt;INFO&gt; TO all neighbors</div><div class="line">    informed = TRUE;</div><div class="line">R:  &#123;A message &lt;info&gt; received&#125;</div><div class="line">IF NOT informed, then:</div><div class="line">SEND &lt;INFO&gt; TO all other neighbors;</div><div class="line">informed = TRUE;</div><div class="line">FI</div></pre></td></tr></table></figure><p><em>Are several competing initiators allowed???</em></p><h3 id="evaluation-of-flooding"><a href="#evaluation-of-flooding" class="headerlink" title="evaluation of flooding"></a>evaluation of flooding</h3><p>suppose $n$ nodes and $e$ edges.</p><ul><li><p>how many messages are sent?</p><p>1) each node sends message to all its incident edges: $2e$</p><p>2) except the node which sent message to itself: $-n$</p><p>3) except the initator: $+1$</p><p>Thus, $2e-n+1$ messages are sent.</p></li><li><p>how to determine the termination? </p><p>=&gt; Confirmation</p></li></ul><h3 id="flooding-with-confirmation"><a href="#flooding-with-confirmation" class="headerlink" title="flooding with confirmation"></a>flooding with confirmation</h3><p>Two types of messages: <em>Explorers</em>, <em>confirmations</em></p><p>A process acknowledges an explorer with a confirmation, when it receives all confirmations for the explorers it sent.</p><p>If this process received the explorer for the first time, it sent confirmation after arrival of #neighbor -1 receipts, if it is leaf or received further explorer, sent confirmation immediately.</p><p>If the initiator received a confirmation from every neighbor, algorithm terminates.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">I:  &#123;Not informed&#125; // executed by the initiator</div><div class="line">SEND &lt;Explorer&gt; TO all neighbors;</div><div class="line">informed = TRUE;</div><div class="line">R:  &#123;explorer from neighbor N is received&#125;</div><div class="line">IF NOT informed, then:</div><div class="line">SEND &lt;Explorer&gt; TO all neighbors except N;</div><div class="line">informed = TRUE;</div><div class="line">A = N;</div><div class="line">ELSE:</div><div class="line">SEND Confirmation to N;</div><div class="line">FI</div><div class="line"></div><div class="line">&#123;Confirmation is received&#125;</div><div class="line">Count = Count + 1;</div><div class="line">IF (NOT Initiator) &amp;&amp; (Count == #Neighbors -1), then:</div><div class="line">SEND Confirmation TO Neighbor A;</div><div class="line">FI</div><div class="line">IF Initiator &amp;&amp; (Count == #Neighbors), then:</div><div class="line">Exit;</div><div class="line">FI</div></pre></td></tr></table></figure><h3 id="evaluation-of-flooding-with-confirmation"><a href="#evaluation-of-flooding-with-confirmation" class="headerlink" title="evaluation of flooding with confirmation"></a>evaluation of flooding with confirmation</h3><ul><li><p>how many explorers altogether?</p><p>every node sends explorers to its neighbors: $2e$ explorers</p><p>not include its activation edge: $-n$ explorers</p><p>except the initiator: $+1$ explorer</p><p>total: $2e - n + 1$ explorer</p></li><li><p>how many confirmations altogether?</p><p>$2e - n + 1$ confirmations</p></li><li><p>how many messages altogether?</p><p>$4e - 2n + 2$ messages</p></li></ul><h2 id="Echo"><a href="#Echo" class="headerlink" title="Echo"></a>Echo</h2><p>Begin with the initiator, it sends explorers to all its neighbors. If a node received the explorer for the first time, it records the activation edge and sends explorers to all its neighbors. If two explorers meet on an edge, the explorers are swallowed. </p><p>For a node have received an explorer before, if it receives an explorer or echo over all its edges, then it sends echo over its activation edge, leaf nodes immediately send echo when receive an explorer.</p><p>The algorithm terminates when the initiator receive echo.</p><p>Exactly two messages run over every edge.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">I:  &#123;NOT informed&#125; // executed by the initiator</div><div class="line">SEND &lt;EXPLORER&gt; to all its neighbors</div><div class="line">informed = True;</div><div class="line">R:  &#123;a message from neighbor N is received&#125;</div><div class="line">IF NOT informed, then:</div><div class="line">SEND &lt;Explorer&gt; to all other neighbors except N;</div><div class="line">informed = TRUE;</div><div class="line">A = N;</div><div class="line">FI</div><div class="line">count = count + 1;</div><div class="line">IF count == #neighbors, then:</div><div class="line">IF NOT Initiator:</div><div class="line">SEND &lt;ECHO&gt; TO neighbor A;</div><div class="line">ELSE:</div><div class="line">EXIT;</div><div class="line">FI</div><div class="line">FI</div></pre></td></tr></table></figure><h3 id="Evaluation-of-echo"><a href="#Evaluation-of-echo" class="headerlink" title="Evaluation of echo"></a>Evaluation of echo</h3><p>every node sends an explorer on all edges -&gt; $2e$ explorer</p><p>exception activation edge -&gt; $-n$ explorer</p><p>except the initiator -&gt; $+1$ explorer</p><p>every node sends an echo on the activation edge -&gt; $+n$ echos</p><p>except the initiator -&gt; $-1$ echo</p><p>totally, $2e$ messages.</p><h3 id="Characteristics-and-Difference-with-flooding"><a href="#Characteristics-and-Difference-with-flooding" class="headerlink" title="Characteristics and Difference with flooding"></a>Characteristics and Difference with flooding</h3><p>Echo is a <em>wave algorithm</em></p><ul><li>Distribution of information (to all nodes over all edges)</li><li>Collecting of information (of potentially all nodes over the activation edges)</li></ul><p>与flooding with confirmation相比，对于二者的节点来说，如果都是第一次收到explorer，会将explorer发给所有其他邻居；在confirm阶段，echo算法中节点只会将确认消息echo回给第一个给它发explorer的节点，而在flooding算法中，节点会发送confirmation给每一个给它发过explorer的节点以确认它收到了explorer。采用echo算法可以少发一些message。</p><p>Echo-edges form a spanning tree, the spanning tree looks different due to the message delays</p><h3 id="improvement-of-Echo-algorithm"><a href="#improvement-of-Echo-algorithm" class="headerlink" title="improvement of Echo algorithm"></a>improvement of Echo algorithm</h3><p>Idea: avoid visit nodes which are known to be visited by other explorers. 减少echo算法中发送的explorer数量。</p><p>implement: Together with an explorer, a set of taboo nodes $z$ is sent and received.</p><p>$z = <neighbors of="" initators=""> \cup <initiator>$</initiator></neighbors></p><p>Explorers only sent to neighbors set $y$ which is not included in z</p><p>Thus, the new taboo nodes set $z’ = z \cup y$</p><h2 id="Broadcast"><a href="#Broadcast" class="headerlink" title="Broadcast"></a>Broadcast</h2><p>sending of a message to all nodes, optionally with confirmation.</p><p>flooding algorithm is especially fault-tolerant because all edges are used for distribution of information, it is suitable for any connected undirected topology.</p><p>However, when focus on some specific topology, we don’t need to use all edges to send information, a broadcast with less messages is possible. For aimed case, each node is only reached over a single edge, only $n-1$ messages.</p><ul><li>Broadcast on unidirectional rings: all nodes are informed when the initiator receive the token again, $n$ messages.</li><li>Broadcast on Trees: Tree has $n-1$ edges (spanning tree?)</li><li>Broad cast on Hypercubes: time complexity – $d$ (#dimension) cycles; Message complexity: $n-1$</li></ul><h2 id="Multicast"><a href="#Multicast" class="headerlink" title="Multicast"></a>Multicast</h2><p>pairwise exchange messages is not optimal if communications are between a sender and many receivers.</p><p><em>Multicast operatioin</em> is to send a single message from one process to each member of a group processes (if send know its members who are in same group…)</p><p>Why multicast? </p><ul><li>Fault tolerance: client requests are multicast to a group of identical, replicated servers, even a server failed, the client still can be served.</li><li>Service discovery: use multicast we can discover services</li><li>Better performance through replicated data: multicast messages can be used to propagate changes to all copies.</li><li>event notifications: notify a group of processes when a new event happened.</li></ul><h3 id="Reliable-IP-Multicast"><a href="#Reliable-IP-Multicast" class="headerlink" title="Reliable IP Multicast"></a>Reliable IP Multicast</h3><p>can be implemented using <em>piggybacked acknowledgements and negative acknolwedgements</em></p><ul><li>piggyback ack: ack of delivery is attached to other message</li><li>negative ack: ack notify other process that a message is missing</li><li>use “deliver” instead of “receive”</li></ul><p>$S^p_g$ is denoted as the sequence number of process $p$ in group $g$, we can take it as how many messages this process multicast.</p><p>$R^q_g​$ is denoted as the sequence number(the number of messages) that current process delivered(received) from process $q​$ in group $g​$.</p><p>for a specific process $p1, p2, p3$ in group $g$, their $S^p_g$ and $R^q_g$ are all set to 0 initially.</p><ol><li>if $p1$ multicast a message, $S^{p1}_g$ will add 1.</li><li>then $p1, p2, p3$ received the message multicast from $p1$, $p2$’s $R^{p1}_g$ and $p3$’s $R^{p1}_g$ will both add 1.</li><li>After that, if $p2$ wants to multicast a message $m$, it piggybacks its sequence number $S^{p2}_g$ and a set of acknowledgements of the form $<q, r^q_g="">$, like $ m = { payload, 0, <1, 1=""> } $ </1,></q,></li><li>$p3$ and $p1$ received new message from $p2$, they will compare the piggybacked sequence number with their own $R^{p2}_g$ </li><li>take $p3$ as example, if $p3$’s $R^{p2}_g $ equals to the sequence number $S^{p2}_g$ of $p2$, the message will be delivered; if $S^{p2}_g \le R^{p2}_g$ (p2发出的比p3收到的少), the message has been seen before and is discarded; if $S^{p2}_g \ge R^{p2}_g$ (p2发出的比p3收到的多，可能有消息丢失), the message is stored in a <em>hold-back queue</em> and missing message are requested before delivery, then a negative ack is sent to either the sender or any other process which have delivered the missing message.<br>​</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;Explain the Echo/Broadcast/Flooding algorithm.&lt;/li&gt;
&lt;li&gt;What are the differences?&lt;/li&gt;
&lt;li&gt;What is the message complexity?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Overview:&lt;/p&gt;
&lt;p&gt;Flooding:distribute info, with/without confirmation, all nodes and edges&lt;/p&gt;
&lt;p&gt;Echo:distribute info, all nodes and edges, selective confirmation, collect info, spanning tree&lt;/p&gt;
&lt;p&gt;Broadcast:distribute, all nodes, without acknowledgement with special topologies&lt;/p&gt;
&lt;p&gt;Multicast: distribute, specific group, with/without acknowledgement&lt;/p&gt;
    
    </summary>
    
      <category term="notes" scheme="http://yoursite.com/categories/notes/"/>
    
    
      <category term="TUBcourse" scheme="http://yoursite.com/tags/TUBcourse/"/>
    
      <category term="Distributed Algorithm" scheme="http://yoursite.com/tags/Distributed-Algorithm/"/>
    
  </entry>
  
  <entry>
    <title>Review of HSI</title>
    <link href="http://yoursite.com/2017/02/12/HSIreview/"/>
    <id>http://yoursite.com/2017/02/12/HSIreview/</id>
    <published>2017-02-12T07:50:12.000Z</published>
    <updated>2017-02-14T16:58:40.000Z</updated>
    
    <content type="html"><![CDATA[<p>A review of IE elective course – Human Side of Innovation</p><a id="more"></a><h2 id="exam-spoiler"><a href="#exam-spoiler" class="headerlink" title="exam spoiler"></a>exam spoiler</h2><h3 id="general-questions"><a href="#general-questions" class="headerlink" title="general questions"></a>general questions</h3><ul><li>2 longer questions and some smaller ones</li><li>60 min</li><li>most open questions, some “name/expain” questions</li><li>no math</li><li>know what papers talk about, the problems try to solve, conclusion</li></ul><h3 id="sample-questions"><a href="#sample-questions" class="headerlink" title="sample questions"></a>sample questions</h3><h4 id="Creativity"><a href="#Creativity" class="headerlink" title="Creativity"></a>Creativity</h4><p>use theories in class to explain how to foster creativity. </p><p><em>creativity: The production of novel and useful ideas in any domain. It must be different from what has been done before.</em></p><p><em>innovation: Innovation is the successful implementation of creative ideas.</em></p><p>innovation是creativity的实现</p><ul><li><p><strong>Amabile’s Model ???</strong></p><ol><li><p>task motivation stimulates your task motivation so that you have external or internal motivation to finish the task, also task motivation can make you learning domain-relevant skills.</p></li><li><p>Then you need to prepare to solve the task, in this process you can search and store relevant information for preparation via your experience and domain knowledge.</p></li><li><p>Next, search memory and generate response possibility according to the situation, this step also requires task motivation and creativity-relevant skills because it needs creative, innovative solutions for the current problem.</p></li><li><p>use domain-relevant skills to validate if your response is correct or effective.</p></li><li><p>modify, iterate according to the outcome and feedback.</p><p>提出问题，搜集背景资料，提出假设，验证假设，迭代反馈</p></li></ol></li></ul><p><img src="/img/005.png" alt="amabile&#39;s model"></p><ul><li>3 components of Creativity</li></ul><ol><li><p>task motivation (intrinsic and extrinsic)</p></li><li><p>domain relevant skills (knowledge, skills in a specific field)</p></li><li><p>creativity relevant skills (knowledge of techniques to produce creative ideas)</p><p><em>how to increase these three components?</em></p><p>内在兴趣驱动和外部因素（压力）驱动，使用相关领域知识，结合创新方法进行creativity和innovation</p><p>​</p></li></ol><table><thead><tr><th>motivation influences</th><th>positive social-environmental influences</th></tr></thead><tbody><tr><td>intrinsic</td><td>free and autonomy, optimal challenge, task match interests</td></tr><tr><td>extrinsic</td><td>competence, strategic direction, sufficient resources</td></tr></tbody></table><p>​       </p><table><thead><tr><th>skills</th><th>ofganizational support</th></tr></thead><tbody><tr><td>domain-relevant skills</td><td>provide relevant trainning, support for critical factors, task match skills</td></tr><tr><td>creativity-relevant skills</td><td>encourage unconventional thinking, support alternative solutions, time to fully capture problems, teach creativity techniques</td></tr></tbody></table><ul><li><p>threats of brainstorming (explain) <em>slides P46</em></p><p>Brainstorming: ideas can be wild, out-of-box, one time one talking, no judgements, stay focus, visual, as many as possible, be realistic finally</p><p><em>three main problems: inefficient, dominant people, too unstructured.</em></p><ol><li><p>production blocking   </p><ul><li>flow of thought may be interrupted</li><li>while others speaking, one idea may be blocked and forgotten because one talking one time</li></ul></li><li><p>social loafing</p><ul><li>participants may not work as hard as they would alone</li></ul></li><li><p>evaluation anxiety and conformity</p><ul><li>fear receive negative evaluation</li><li>fear to be diverse, stick similar ideas</li></ul></li><li><p>downward norm setting(不是很明白这个点┑(￣Д ￣)┍)</p><ul><li><p>performance across group members often converges</p></li><li><p>brainstorming participants tend to match their performance to the least productive members</p><p>$solutions$ : electronic brainstorming （网上写然后每个人的观点都po）</p><p>​             Nominal group technique(IGI，每个人独立写下自己的idea，小组讨论，个人单独评估)</p><p>​             Diversification of the team (membership change)</p><p>​                     Trained facilitators (不能重复别人的观点)</p></li></ul></li></ol></li><li><p>job satisfaction/dissatisfaction affect innovative (integreted or minicase)（<em>sides P63</em>)</p><p>job satisfaction linked to positive performance</p><p>However, discontentment can be a trigger for action if a company needs change</p><p>job dissatisfaction will have strongest positive affect for creativity when:</p><ul><li><p>when continuance commitment is high and coworkers provide useful feedback.</p></li><li><p>continuance commitment and coworker helping and support are both high.</p></li><li><p>continuance commitment and perceived organizational support for creativity are bot high.</p><p>快速响应改进，同事、组织帮助支持</p></li></ul></li><li><p>影响creativity的因素（不知道要不要考，剧透里没提到O__O “…）</p><ul><li>employee motivations has 3 types of goal orientations:<ol><li>learning orientation（想学新知识和技能）</li><li>performance prove orientation (想展示自己比别人表现得更好)</li><li>performance avoidance orientation (担心效率低下不能很好完成任务)</li></ol></li><li>bureaucracy factors<ol><li>centralization (层级化明显)</li><li>formalization (rules和standardized procedures)</li></ol></li></ul><p>centralization低时，learning orientation 促进creativity，performance avoidance orientation对creativity没那么大的负面影响</p><p>formalization低时，performance prove orientation促进creativity, performance avoidance orientation消极影响更明显</p><p>​</p></li></ul><h4 id="Teams"><a href="#Teams" class="headerlink" title="Teams"></a>Teams</h4><p>definition of Team: a social system of two or more people, in an organization, share common identity, collaborate on comon task.</p><ul><li><p>know and explain why three aspects influence decision to free ride and how to minimize it</p><ul><li>larger team size，higher incentives to free-ride</li><li>more homogeneous, lower incentives to free-ride</li><li>relations within the team</li><li>observability of effort</li><li>punishments</li><li>norms</li></ul></li><li><p>answer certain number of chances and risks about teamwork for organisation and employees</p><p>chances:</p><p><img src="/img/009.png" alt="选区_009"></p><p>risks:</p><p><img src="/img/010.png" alt="选区_010"></p></li><li><p>incentives for teams (没在剧透里提到)</p><ul><li>explicit: team bonus, profit sharing, stocks</li><li>implicit: norms (to improve team coordination and spirit, but how to establish suitable norms, supervision, exemplifying and adaptation of norms could be problem)</li><li>explicit incentives are not detrimental to creativity, incentives need to fit to the type of task</li><li>output is highest when the “impact” of an idea is rewarded</li><li>the amount of exploration is higher if participants are rewarded for their impact</li></ul></li><li><p>common problem with teamwork, why happen and how to overcome</p><ul><li><p>Free-Riding problem (有人划水= =，may cause motivation decrease, team members reduce effort)</p><p><strong>Individual effort in the team is inefficiently low(???)</strong></p><ol><li>each team member bears the marginal costs of his effort individually, marginal benefits are divided among N team members, thus the marginal benefit resulting from individual effort is lower than team’s marginal benefit from individual effort.</li><li>persons who are just interested in their own well being will thus work less hard than optimal</li></ol></li><li><p>coordination effort (transaction costs)</p></li></ul></li><li><p>best size for a team and why</p><p>我猜是it depends. 取决于成员专长、任务性质等等还要考虑free ride</p></li><li><p>how to integrate employees from two different companies (difficult question)</p><p>太多diversity可能不利于团队的performance，但diversity可以减轻free-ride，需要权衡</p></li><li><p>explain the model of Hackmans model (more general)</p><p><img src="/img/011.png" alt="选区_011"></p><p>​</p><p>three process criteria of effectiveness proposed by Hackman:</p><ol><li>effort applied to the group task<ul><li>group design: structure of the task, work will be perceived as meaningful leading to higher effort.</li><li>organization context: reward system, focus on group rewards and objectives, give positive consequences for excellend performance</li><li>group synergy: minimize coordination and motivation losses, create shared commitment</li></ul></li><li>amount of knowledge and skill applied to the group task<ul><li>group design: composition of the group, 个人有专业性，团队size合适，成员间求同存异</li><li>organizational context: education system， 组织帮助个人成长</li><li>group synergy: 不偏心团队成员，foster collective learning</li></ul></li><li>task-appropriate performance strategies<ul><li>group design: clear and intense norms, norms support to be adaptable</li><li>organizational context: clarity about parameters of performance situation(清楚任务要求，可用的资源和人), access to data about likely consequences of different strategies (能估计不同策略带来的结果)</li><li>group synergy: minimize slippage(减少划水?), create innovative strategic plans</li></ul></li></ol></li><li><p>TWQ（剧透没提，不知道要不要考不过感觉挺重要(#‵′)）</p><p>a comprehensive measure of the quality of cooperations in teams</p><ul><li>communication: team members communicate frequently, directly, personally, spontaneously, information shared openly, preciesely and useful (团队成员之间友好亲切直接交流不要套路)</li><li>coordination: closely harmonized subtasks, clear fully comprehended and accepted by all members (大家都同意的合理分工)</li><li>balance of member contributions: avoid imbalance of contributions, recognize individuals potential</li><li>mutual support: help each other, less conflicts, suggestions are respected, able to reach consensus (团员互相帮助尊重彼此达到共识)</li><li>effort: everyone fully pushes, puts much effort</li><li>cohesion: feel proud of the team, personal attraction among members</li></ul><p>​</p></li></ul><h4 id="Interactive-value-creation"><a href="#Interactive-value-creation" class="headerlink" title="Interactive value creation"></a>Interactive value creation</h4><p>trade-offs of cooperate or make by self</p><p><img src="/img/012.png" alt="选区_012"></p><ul><li><p>know and explain main kinds of information required for innovation mgmt (slides 125)</p><ol><li><p>solution information （解决方案是否满足需求）</p><p>how can a certain need be satisfied with a product or service?</p><p>what kind of principles, methods to solve the problem?</p><p><em>may encounter local search bias (总是用老办法是不行滴，要想新办法)</em></p></li><li><p>need information (客户有啥需求)</p><p>utility and preference of customers</p><p>what kind of problem should be solved?</p><p>this kind of information allos to put the right innovation to the market.</p><p><em>may encounter sticky problem</em></p></li></ol></li><li><p>explain the problem of sticky information for innovation mgmt (<em>slides 128</em>)</p><p>sticky information: a problem when access need information. Access to customers often difficult, needs are often hard to articulate.</p><p>Solvement: User integration.</p></li><li><p>know one of the methods of user integration and explain how this method works</p><blockquote><p>when the user is (partly) the product creator, successful products will arrive. </p></blockquote><ul><li><p>Lead user methods</p><p>see below</p></li><li><p>observe users in communities</p><ul><li><p>empathic design: 通过视奸（不是提问）客户使用产品的情况确定客户潜在需求</p><p>goal: </p><ol><li>gather information about customer habits, interaction of product with consumers environment, assessment of product features, needs not articulated yet.</li><li>achieve breakthrough, accelerate product development cycles</li><li>improve products via commercializing innovations already developed</li></ol><p>requirements:</p><ol><li>specialists and methodological knowledge</li><li>short process, longer preparation</li><li>low to medium resource demand</li><li>good opportunities for outsourcing to specialized agencies</li></ol><p>how to apply it?</p><ol><li>search field definition: define users for observation, issues should be focus on, research team</li><li>capturing data</li><li>evaluation and documentation</li><li>reflection and analysis</li></ol><p>benefits:</p><ol><li><p>gathering a differentiated picture of the needs of customers</p></li><li><p>determine latent needs of customers</p></li><li><p>rather low cost, low risk</p></li><li><p>create opportunities for differentiation strategies</p><p><em>cannot replace market research</em></p></li></ol></li><li><p>netnography</p><p>what is netnography: a qualitative research approach to analyze the customer and user dialogues in existing online communities(视奸用户的评论= =)</p><p>goal:</p><ol><li>typologies of user groups</li><li>identification of user innovations, user generated contents, product prototypes</li><li>identification of opinion leaders, lead users</li></ol><p>requirements:</p><ol><li>process community input</li><li>user input data</li><li>find relevant user input</li><li>specilized agencies’ support</li></ol><p>how to apply it?</p><ol><li>search field definition: systemize topics, trends, markets, products</li><li>identificate and select online communities and source</li><li>community observation, data gathering</li><li>qualitative in depth analysis of consumer insights</li><li>insight translation into product solutions</li></ol><p>benefits:</p><ol><li>gain unbiased consumer insights without informing competitors</li><li>classify and posit products within a perceptual map</li></ol><p>cons:</p><ol><li>solutions can be biased by selection of inputs</li><li>companies often lack the capability to communicate with communities</li><li>hard to evaluate large quantities of data</li><li>hard to test your findings</li></ol></li></ul></li><li><p>ideation contests</p></li><li><p>user toolkits for innovation</p></li></ul><p>​</p></li><li><p>know and explain lead user method, how it works</p><p>what is lead user methods?</p><ul><li>idea: collaborate with these lead users to generate innovative concepts with functional novel elements, use specific search techniques to identify lead users, work with lead users in concept generation workshops to codevelopt. </li><li>goal: innovative insights into technical solutions, generating trend explorations, identification of product requirements from user perspective, identification of innovative ideas to diversify business activities.</li><li>requirements: high resource effort, senior developers of products also need to participate, dedicated training in lead user identification.</li></ul><p>how to apply lead user methods?</p><ul><li>define project team and project objectives</li><li>analyze trends and needs in search fields</li><li>identificate eligible lead users and encourage them to participate</li><li>foster concept generation, evaluate and refine ideas</li></ul><p>benefits of using Lead user method (how it works)</p><ul><li>identification of strong market opportunities</li><li>concepts are developed with direct input from “lead users”</li><li>get new products and services faster to the market</li></ul></li></ul><ul><li><p>benefits and disadvantages of user integration (but in specific situation)</p></li><li><p>two problems of innovation mgmt </p><p>slides P189有考试剧透</p></li></ul><h4 id="Leadership"><a href="#Leadership" class="headerlink" title="Leadership"></a>Leadership</h4><blockquote><p>The ability to influence, motivate, and enable others to contribute to the effectiveness and success of the organization.</p><p>management is coping with complexity, while leadership is coping with change</p></blockquote><ul><li><p>name and describe two transformational and transactional leadership factors</p><ul><li>transactional leadership (managerial leadereship)<ul><li>exchange-oriented leadership (奖惩分明)</li><li>focus on increasing the efficiency of established routines and procedures, more concerned with following existing rules than with making changes to the structure of the organization. (强调规则纪律)</li><li>factors:<ol><li>laissez-Faire: 缺少领导力，不干预，放养</li><li>passive management-by-exception: 出了问题才处理</li><li>active management-by-exception: keep tracks of all mistakes, monitor subordinates</li><li>contingent reward: set performance goals, clarify expectations, give recognition upon goal attainment.</li></ol></li></ul></li><li>transformational leadership<ul><li>visionary, inspirational and stimulating leadership engender higher performance and satisfaction of employees (鼓励型领导)</li><li>share vision of future, support subordinates, recognize individual difference, sets high expectations</li><li>factors:<ol><li>idealised influence (behavioural): communicate mission and values，跟员工讲他们的重要价值，让员工觉得自己很重要</li><li>idealised influence (attributed): perceived as exceptional, confident and trustworthy, 让员工以为老板打工为傲</li><li>inspirational motivation: articulate visions and share goals optimiscally and enthusiastically </li><li>intellectual stimulation: encourage others to develop new approaches, 鼓励从多角度看问题</li><li>individualised consideration: provide coaching, treat subordinates on a one-to-one basis, 帮助员工成长</li></ol></li></ul></li></ul></li><li><p>why transformational leadership is associated positively with innovation</p><p>从transformational leadership的factors回答应该就可以吧我猜。</p><p>有几个文章比较两种方式哪个好，结果是</p><ol><li>transformational leadership有利于fluence and flexibility in brainstorming groups</li><li>在financial service organizations中，transformaitonal leadership更支持创新，员工表现也更好，</li><li>Transformational leadership positively predicted organizational-level innovation through enhanced support for innovation</li><li>提升员工的work engagement</li></ol></li><li><p>the difference between transformational leadership and transactional leadership, where to apply appropriately</p><p>感觉还是根据上边的factors答</p></li><li><p>authentic leadership (剧透没提，slides里有)</p><p>authentic leadership positively associated with creativity, job satisfaction, voluntary extra effort, performance and sales</p><p>featues:</p><ul><li>self-awareness: 知道员工的长短处</li><li>relational transparency: 没有套路展示自我想法</li><li>balanced processing: 在决策前悉心听取每个意见</li><li>moral perspective: 用belief驱动action，而不是外部压力</li></ul></li></ul><h4 id="Human-Resources-in-Innovation-Management"><a href="#Human-Resources-in-Innovation-Management" class="headerlink" title="Human Resources in Innovation Management"></a>Human Resources in Innovation Management</h4><blockquote><p>get the right people, and get them together, incentivize them correctly</p></blockquote><ul><li><p>how opponents can be both beneficial and detrimentla to innovation progress (difficult)</p><p>​</p></li></ul><ul><li>name two barriers to innovation and what kind of promotors to overocome them</li></ul><p>  to overcome these two barriers:</p><ul><li><p>power promotors (promotors by hierarchical power)</p><p>surmount barriers of will through their hierarchical potential</p></li><li><p>promotors  (promoters by know how)</p><p>surmount barriers of capability through their expert knowledge</p></li></ul><ul><li><strong>principal agent theory</strong>: main assumptions, where to apply, two problems they trigger, how to mitigate the problem</li></ul><blockquote><p>PAT deals with relations and contracts, in particular in situations with asymmetric information.</p></blockquote><p>  PAT的概念看看就好。。感觉并不会直接问概念</p><ul><li><p>two problems:</p><ul><li>certain characteristics of the agent not are not known to the principal (Hidden Information)</li></ul><p>Is it possible to design contracts that makes only “suitable” candidates want to sign, and for agents to submit/reveal their characteristics?</p><p>agents可能有一些principal不知道的状态或信息，这些是外源性(exogenous)的</p><ul><li>agents actions are hard to monitor (hidden action)</li></ul><p>what actions should be taken to monitor the agent? and is it possible to design contracts make agents choose “right” actions?</p><p>agnets有不会被principal观察到的行动，这些信息缺失是内源性(endogenous)的</p></li><li><p>how to reduce uncertainty?</p><ul><li>signalling: a mechanism where agent credibly conveys information about itself to the principle</li><li>screening (opposite of signalling): reveal true characteristics of the agent, principles offer a menu of contracts in order to separate the different types, that is design the contract that only suitable candidates accept it.</li></ul></li><li><p>Hidden action problem:</p><p> Agent’s action are not observable, but their actions influence the outcome of the principal. Principal and agents have different interests, <em>how can the principal induce the agents to choose their actions in the principal’s interest?</em></p><ul><li><p>reduce informaiton assymmetry (monitoring)</p><p>principal wants to control agent’s actions via monitoring, it will lead to direct costs (like cameras, supervisors) and indirect costs (like trust issues, reduce creativity)</p></li></ul></li></ul><pre><code>- alignmetn of interests  1. performance based payments     may face constraints that need to provide sufficient incentives and proper kind of incentives.     may face *Moral Hazard*: 参与合同的一方所面临的对方可能改变行为而损害到本方利益的风险.(缺少不违约的激励)     if performance based payments doesn&apos;t work, you should make employees feel like a part of the organization, ensure the security of workers and more effort is not a downside, make them believe company success is individuals&apos; success  2. change working conditions</code></pre><ul><li><p>main difference between human capital and signalling theory, explain them, describe singalling theory in general, where need to apply it   <em>(slides P218 – 223 用学历和生产力的关系举例)</em></p><ul><li><p>human capital theory explains differences due to different stock in human capital(knowledge, skills…), namely education increases productivity</p></li><li><p>signaling theory provides an alternative expalnation which maintains education certificates reveal productivity.</p><p>看的不是很明白。。感觉好像一个是看即时成果一个是看潜力</p></li></ul></li><li><p>roles in innovation process</p><ul><li><p>the “champion”: someone who pushes an innovation.</p><p>direct motivational influences:</p><ul><li>expresses enthusiasm and confidence</li><li>persists under adversity</li><li>gets the right people involved</li></ul></li></ul></li></ul><ul><li><p>promoter roles</p><p>barriers, power-bases and contributions define a promotor role</p><ul><li>persons which actively and intensively support an innovation</li><li>start an innovation process</li><li>sustain a high activity level</li><li>terminate the decision process</li></ul></li><li><p>other classification of promotors:</p><ol><li><p>process promotor: 选人、联系sponsors和experts、跟进流程、领导创新团队</p></li><li><p>relationship promotor：social, external networks, find external parterners, plans, build trust</p></li><li><p>technological gatekeeper: expert knowledge</p></li></ol></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;A review of IE elective course – Human Side of Innovation&lt;/p&gt;
    
    </summary>
    
      <category term="notes" scheme="http://yoursite.com/categories/notes/"/>
    
    
      <category term="TUBcourse" scheme="http://yoursite.com/tags/TUBcourse/"/>
    
      <category term="BusinessCourse" scheme="http://yoursite.com/tags/BusinessCourse/"/>
    
  </entry>
  
  <entry>
    <title>HSI review 2 -- sample question and answer</title>
    <link href="http://yoursite.com/2017/02/12/HSIreview2/"/>
    <id>http://yoursite.com/2017/02/12/HSIreview2/</id>
    <published>2017-02-12T07:50:12.000Z</published>
    <updated>2017-02-13T23:16:16.000Z</updated>
    
    <content type="html"><![CDATA[<p>some sample questions from spoiler.</p><a id="more"></a><h2 id="Creativity"><a href="#Creativity" class="headerlink" title="Creativity"></a>Creativity</h2><p>sample question</p><p><img src="/img/选区_020.png" alt="选区_020"></p><ol><li>workplace culture encourages innovation of employees. That’s an extrinsic innovation fluence. People who work in a environment which gives them freedom and competence will make them more active in innovation.</li></ol><ol><li><p>Google emphasize on diversity, which is a important character of innovation. As we all know, diversity can bring the crash between ideas, also </p></li><li><p>related to task motivation.</p><p>because of the work in Google is challenging, employees can be stimulated their task motivation so that they have external or internal motivation to finish the task, and learn domain-relevant skills.</p></li><li><p>people core – human resource</p></li><li><p>human resource, make employees secure.</p></li></ol><h2 id="Teams"><a href="#Teams" class="headerlink" title="Teams"></a>Teams</h2><p><img src="/img/选区_021.png" alt="选区_021"></p><ol><li>the <strong>free rider problem</strong> occurs when those who benefit from resources, goods, or services do not pay for them, which results in an underprovision of those goods or services. <a href="https://en.wikipedia.org/wiki/Free_rider_problem" target="_blank" rel="external">wiki</a></li><li>choose proper team size. Make members feel they are important and responsible for the team. Make members’ individual profit related to the outcome of assembling toys. Punish free-riding. </li><li>still work</li><li>if the team is composed of very heterogeneous members with heterogeneous tasks, it is more difficult to observe and judge individual effort. </li><li>coordination effort, transaction costs…etc</li></ol><h2 id="Interactive-Value-Creation"><a href="#Interactive-Value-Creation" class="headerlink" title="Interactive Value Creation"></a>Interactive Value Creation</h2><p><img src="/img/选区_022.png" alt="选区_022"></p><ol><li><ul><li>solution information, to figure out if costumers are satisfying to the product.</li><li>need information, to figure out what needs do costuemrs have.</li></ul></li><li><p>sticky information: a problem when access need information. Access to   customers often difficult, needs are often hard to articulate.</p><p> Solvement: User integration, includes lead user methods, observe users in communities, netnography, ideation contests, user toolkits for innovation.</p></li><li><p>see HSI review1</p></li></ol><h2 id="Leadership"><a href="#Leadership" class="headerlink" title="Leadership"></a>Leadership</h2><p><img src="/img/选区_023.png" alt="选区_023"></p><ol><li><ul><li><p>transformational is a kind of leadership that is exchange-oriented. It focus on increasing the efficiency of established routines and procedures, more concerned with existing rules than making changes. Its factors are:</p><p>laissez-Faire, passive management by exception, active management by exception, contingent reward.</p></li><li><p>transformational leadership is a kind of leadership that leaders inspire, encourage employees to pursue higher performance and satisfaction. Its factors are:</p><p>idealized influence in behavior and in attribute, inspirational motivation, intellectual stimulation, individualized consideration</p></li></ul></li><li><ul><li>has benefits on influences and flexibility in brainstorming groups</li><li>improve employees’ work engagement</li><li>positively predicted organizaitional-level innovation</li><li>encourage, make workers secure and satisfied</li></ul></li></ol><h2 id="Human-Resource-Mgmt"><a href="#Human-Resource-Mgmt" class="headerlink" title="Human Resource Mgmt"></a>Human Resource Mgmt</h2><p><img src="/img/选区_024.png" alt="选区_024"></p><p>see last passage.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;some sample questions from spoiler.&lt;/p&gt;
    
    </summary>
    
      <category term="notes" scheme="http://yoursite.com/categories/notes/"/>
    
    
      <category term="TUBcourse" scheme="http://yoursite.com/tags/TUBcourse/"/>
    
      <category term="BusinessCourse" scheme="http://yoursite.com/tags/BusinessCourse/"/>
    
  </entry>
  
  <entry>
    <title>coprocessing and GPU</title>
    <link href="http://yoursite.com/2017/02/04/coprocessing/"/>
    <id>http://yoursite.com/2017/02/04/coprocessing/</id>
    <published>2017-02-04T07:50:12.000Z</published>
    <updated>2017-02-13T18:53:37.000Z</updated>
    
    <content type="html"><![CDATA[<p>This chapter talks about gpu and coprocessing.<br><a id="more"></a></p><h1 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h1><p>Modern Porcessors has performance limitations, because the number of transistors on a chip keeps growing quickly while the power density of transistors was constant.</p><p><em>constant chip size and increasing number of transistors increases overall power consumption and the produced heat.</em></p><p>Thus, cooling and energy consumption became two limits on the amount of power a processor can use. <strong>Modern processors are limited by a fixed energy budget</strong></p><p>To remain in the power constraints, modern proceessors can operate with lower clock rate or turn of parts of the chip, but how to use increasing number of constraints?</p><p><strong>Future machines are expected to consist of a set of heterogeneous processors, each processor is optimized for a certain application scenario.</strong></p><p>For database, we can use these processors to accelerate query processing.</p><h1 id="GPU-architecture"><a href="#GPU-architecture" class="headerlink" title="GPU architecture"></a>GPU architecture</h1><p>For GPU, data copying host, invocate computer kernels and kernels run asynchronously.</p><h2 id="Threads-on-GPU"><a href="#Threads-on-GPU" class="headerlink" title="Threads on GPU"></a>Threads on GPU</h2><p>keep things simple</p><ul><li>don’t try to reduce latency, but hide it</li><li>assume data parallelism and restrict synchronization</li><li>hardware thread scheduling</li></ul><h2 id="CPUs-vs-GPUs"><a href="#CPUs-vs-GPUs" class="headerlink" title="CPUs vs. GPUs"></a>CPUs vs. GPUs</h2><p>CPU: task parallelism</p><ul><li>relatively heavyweight threads</li><li>each thread managed explicitly</li><li>threads run different code</li></ul><p>GPU: data parallelism</p><ul><li>lightweight threads</li><li>threads scheduled in batches</li><li>all threads run same code</li></ul><h1 id="Relational-Co-processing-on-GPUs"><a href="#Relational-Co-processing-on-GPUs" class="headerlink" title="Relational Co-processing on GPUs"></a>Relational Co-processing on GPUs</h1><h2 id="Selection"><a href="#Selection" class="headerlink" title="Selection"></a>Selection</h2><p>choose a subset of tuples from a relation R satisfying a predicate and discard the rest.</p><p>How to parallelize selections efficiently?</p><ul><li>concurrent may writes corrupt data structures</li><li>latching may serialize threads and nullify the preformance</li></ul><p><strong>Key idea: Pre-compute write locations</strong></p><ol><li><p>Prefix Scans: important building block for parallel programs, given an input array $R<em>{in}, R</em>{out}$ is computed as: $R<em>{out}[i] = R</em>{in}[0] + … + R<em>{in}[i-1] (1 \le i&lt;|R</em>{in}|)$, $R_{out}[0] = 0$ <img src="/img/prefix_sum.png" alt="prefix_sum"></p></li><li><p>Parallel Filter: create an array flags of the same size as R and init with zeros</p></li></ol><p><img src="/img/001.png" alt="选区_001"></p><h1 id="Query-Processing-and-Data-Transfer-Bottleneck"><a href="#Query-Processing-and-Data-Transfer-Bottleneck" class="headerlink" title="Query Processing and Data Transfer Bottleneck"></a>Query Processing and Data Transfer Bottleneck</h1><p>Co-processor’s memory capacity quite small, cannot fit all data on it.</p><p>Cache input data in co-processor memory and process data locally as much as possible.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This chapter talks about gpu and coprocessing.&lt;br&gt;
    
    </summary>
    
      <category term="notes" scheme="http://yoursite.com/categories/notes/"/>
    
    
      <category term="TUBcourse" scheme="http://yoursite.com/tags/TUBcourse/"/>
    
      <category term="DatabaseTechnology" scheme="http://yoursite.com/tags/DatabaseTechnology/"/>
    
  </entry>
  
  <entry>
    <title>DBT 07 Concurrency Control</title>
    <link href="http://yoursite.com/2017/02/02/concurrency/"/>
    <id>http://yoursite.com/2017/02/02/concurrency/</id>
    <published>2017-02-02T06:49:04.000Z</published>
    <updated>2017-02-04T12:53:49.000Z</updated>
    
    <content type="html"><![CDATA[<p>This chapter talks about how to use concurrency control to implement isolation and consistency of database, include concurrency execution, serializability theory, 2 phase locking, hierarchical locking, how to deal with deadlocks.</p><a id="more"></a><h2 id="several-definitions"><a href="#several-definitions" class="headerlink" title="several definitions:"></a>several definitions:</h2><ol><li><p>transaction: a unit of work, has multiple data accesses and updates</p><p> transaction introduces two problems:</p><ul><li><p>what to do when system has failure? == Recovery</p></li><li><p>what happens when two transactions try to access the same object? == <strong>Concurrency</strong></p></li></ul></li></ol><ol><li><p>ACID properties</p><ul><li><p>Atomicity: operations only have two states, namely complete or none of them complete</p></li><li><p>Consistency: transactions applied to a consistent database and produce consistent database(preserve integrity constraints)</p></li><li><p>Isolation: A transacion executes as it is the only transaction running in the system</p></li><li><p>Durability: The effects of committed transactions are reflected in the database even after failures</p></li></ul></li><li><p>Transaction Model<br>Assuem we have database items X, Y, Z, …</p><ul><li><p>Ri(X) – Transaction Ti reads item X</p></li><li><p>Wi(X) – Transaction Wi writes item X</p></li><li><p>Ai – Transaction Ti aborts</p></li><li><p>Ci – Transaction Ti commits</p></li></ul></li></ol><p><em>Concurrency: implement isolation and consistency</em></p><h2 id="Concurrency-Execution-–-interleaved-operations"><a href="#Concurrency-Execution-–-interleaved-operations" class="headerlink" title="Concurrency Execution – interleaved operations"></a>Concurrency Execution – interleaved operations</h2><p>Why use concurrency?</p><ul><li><p>use resources efficiently</p></li><li><p>keep fairness of database</p></li><li><p>short transactions don’t need to wait long transactions finished</p></li></ul><h3 id="Serializability-theory"><a href="#Serializability-theory" class="headerlink" title="Serializability theory"></a>Serializability theory</h3><p>interleaved operations may cause inconsistency. So we need a <strong>schedual</strong> which is <em>a partial order of transaction operations that indicates how they interleaved</em>, namely an order of how operations of a transactioni executed.<br>For a correct schedual:</p><ul><li><p>all operations appear in the same order as they appear in transaction</p></li><li><p>a complete order of all conflicting operations of all Ti, Tj is sepcified. </p><p>a <strong>Serial schedual</strong> is a schedual <em>where all oeprations of each transactions appear in consecutive blocks</em></p><p>(the order of transactions can be swapped, but the order of operations in a transaction cannot be swapped)</p></li></ul><h4 id="conflict-conflict-equivalent-conflict-serializable"><a href="#conflict-conflict-equivalent-conflict-serializable" class="headerlink" title="conflict, conflict-equivalent, conflict-serializable"></a>conflict, conflict-equivalent, conflict-serializable</h4><p> for two transactions Ti, Tj:</p><table><thead><tr><th>not conflict</th><th>may conflict</th></tr></thead><tbody><tr><td>ri(X); rj(Y)</td><td>ri(X); wi(Y)</td></tr><tr><td>ri(X); Wj(Y) (X!=Y)</td><td>wi(X); wj(X)</td></tr><tr><td>wi(X);rj(Y) (X!=Y)</td><td>ri(X); wj(X)</td></tr><tr><td>wi(X);wj(Y) (X!=Y)</td><td>wi(X); rj(X)</td></tr></tbody></table><p>operations cannot be swapped when: <strong> two transactions involve same database element and at least one operation is write</strong></p><p>two schedual S and S’, if:</p><ul><li><p>they have same transactions and operations</p></li><li><p>one can be transformed to another via swap non-conflicting operators</p></li></ul><p>Then they are <strong>conflict-equivalent</strong></p><p>if and only if a schedule is conflict-equivalent to some serial schedual, it is <strong>conflict-serializable</strong></p><h4 id="precedence-Graph"><a href="#precedence-Graph" class="headerlink" title="precedence Graph"></a>precedence Graph</h4><p>can check if a schedual S is conflict-serializable</p><p>for a schedual S has transactions T1, T2, action A1 in T1, action A2 in T2, if:</p><ul><li><p>A1 ahead of A2</p></li><li><p>A1 and A2 has the same database element</p></li><li><p>at least one of A1 A2 is write</p></li></ul><p>Then, T1 <em>takes precedence of</em> T2, A1–&gt;A2<br>check the order of actions which have same database element to decide ?–&gt;?, and that’s a directed line in precedence graph.</p><p>If no cycles in precedence graph, then S is conflict-serializable.</p><h2 id="Locking"><a href="#Locking" class="headerlink" title="Locking"></a>Locking</h2><p>locking is used to prevent unserializable behavior</p><ul><li><p>li(X): Ti request a lock on X</p></li><li><p>Ui(X): Ti unlocks its lock on X</p></li></ul><p>Properties:</p><ol><li><p><em>Legality</em>: two transactions cannot lock the same element </p></li><li><p><em>Consistency</em>: Before write or read X, the transaction T needs to lock X, if there is li(X), then there must be a ui(X) after.</p></li></ol><h3 id="2-phase-locking"><a href="#2-phase-locking" class="headerlink" title="2-phase locking"></a>2-phase locking</h3><p>to guarantee that a legal schedual of consistent transactions is conflict-serializable</p><p><strong>1st phase: locks obtained only</strong></p><p><strong>2nd phase: locks relinquished only</strong></p><p>But 2-phase locking cannot prevent deadlocks, when they are waiting each other’s unlocking.</p><h3 id="several-lock-models"><a href="#several-lock-models" class="headerlink" title="several lock models"></a>several lock models</h3><ul><li><p>shared lock (can have many in one transaction) – <strong>used to protect read</strong></p></li><li><p>exclusive lock (only one in one transaction) – <strong>used to protect both read and write access</strong></p></li></ul><p>ri(X) must be preceded by sli(X) or xli(X), wi(X) must be preceded by xli(X)</p><p>requirements:</p><ol><li><p>Consistency: ri(X) after sli(X) or xli(X), and no ui(X) between them; wi(X) after xli(X), no ui(X) neither.</p></li><li><p>Two-phase locking: locking must precede unlocking.</p></li><li><p>Legality: Before unlock, we cannot give same type of lock to same database element from different transactions (such as Ti, Tj).</p></li></ol><p>If you got xli(X), no xlj(X) or slj(X)</p><p>If you got sli(X), no xlj(X).</p><p>The same database element from the same transaction can be locked by share lock and exclusive lock, but it must under the situation that no other transacitons have conflicts.</p><p>Compatability matrix – describe lock management policies</p><table><thead><tr><th></th><th></th><th></th></tr></thead><tbody><tr><td></td><td>S</td><td>X</td></tr><tr><td>S</td><td>yes</td><td>no</td></tr><tr><td>X</td><td>no</td><td>no</td></tr></tbody></table><h3 id="Hierarchical-Locking"><a href="#Hierarchical-Locking" class="headerlink" title="Hierarchical Locking"></a>Hierarchical Locking</h3><p>more fine grained locking ==&gt; better concurrency</p><p>Granularities(top - down) :</p><p>Database – Table – Table partition – Index – Page – Tuple – Index page</p><p>IS: intention to obtain S lock at finer granularity</p><p>IX: intention to obtain X lock at finer granularity</p><p>SIX: S lock on this granularity, intention to obtain X at a finer granularity</p><p>but:</p><pre><code>- lock size increase- big locks force other transactions to wait</code></pre><p>use intention locks to implement hierarchical locking protocol:</p><ol><li><p>start at root</p></li><li><p>have IS or IX on all ancestors to get IS or S</p></li><li><p>To get IX, SIX or X, must have IX or SIX on all ancestors</p></li></ol><table><thead><tr><th></th><th></th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td></td><td>IS</td><td>IX</td><td>SIX</td><td>S</td><td>X</td></tr><tr><td>IS</td><td>Y</td><td>Y</td><td>Y</td><td>Y</td><td>N</td></tr><tr><td>IX</td><td>Y</td><td>Y</td><td>N</td><td>N</td><td>N</td></tr><tr><td>SIX</td><td>Y</td><td>N</td><td>N</td><td>N</td><td>N</td></tr><tr><td>S</td><td>Y</td><td>N</td><td>N</td><td>Y</td><td>N</td></tr><tr><td>X</td><td>N</td><td>N</td><td>N</td><td>N</td><td>N</td></tr></tbody></table><p>The lock manager:</p><ul><li><p>acquireLock(T, X, mode)</p></li><li><p>releaseLock(T, X, mode)</p></li></ul><h2 id="Deal-with-deadlocks"><a href="#Deal-with-deadlocks" class="headerlink" title="Deal with deadlocks"></a>Deal with deadlocks</h2><p>deadlock: 2 transactions are waiting for each other’s locks to be released</p><p>2 ways: delete or avoid deadlocks</p><ul><li>Deadlock avoidance: impose order in which locks can be acquired, transactions notify they need locks in advance, if deadlock happened, abort T rather than blocking it.</li></ul><p>However: transactions usually don’t know if they need locks in advance.</p><ul><li>Deadlock prevention: ABort transactions waiting too long – timeouts</li></ul><p>However: how to pitch timeout parameter?</p><ul><li>Deadlock detection: Ti-&gt;Tj means Ti is blocked waiting for Tj to release a lock. If cycle, then deadlocks happen, roll back releases locks automatically</li></ul><p>Dreadlock algorithm???</p><h2 id="Isolation-levels"><a href="#Isolation-levels" class="headerlink" title="Isolation levels"></a>Isolation levels</h2><p>blocking impair the response time of transactions.</p><p>Some applications can tolerate a bit of “dirtyness”, they don’t always need full serializability.</p><p>=&gt; solution: defining levels of isolation to trade isolation and concurrency.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This chapter talks about how to use concurrency control to implement isolation and consistency of database, include concurrency execution, serializability theory, 2 phase locking, hierarchical locking, how to deal with deadlocks.&lt;/p&gt;
    
    </summary>
    
      <category term="notes" scheme="http://yoursite.com/categories/notes/"/>
    
    
      <category term="TUBcourse" scheme="http://yoursite.com/tags/TUBcourse/"/>
    
      <category term="DatabaseTechnology" scheme="http://yoursite.com/tags/DatabaseTechnology/"/>
    
  </entry>
  
  <entry>
    <title>DBT 08 Recovery from system failures</title>
    <link href="http://yoursite.com/2017/01/30/Recovery/"/>
    <id>http://yoursite.com/2017/01/30/Recovery/</id>
    <published>2017-01-30T21:33:06.000Z</published>
    <updated>2017-02-15T08:37:18.000Z</updated>
    
    <content type="html"><![CDATA[<p>This chapter talks about how to do recovery when database system has crashes. To solve the atomicity and durability, we use logging. It mainly has Undo logging, Redo logging, and Undo/Redo logging. Undo logging records history value, commit after all changes write to the disk, ignore complete transactions; Redo logging records future value, commit before write to disk, ignore incomplete transactions and repeat complete transactions. We also use checkpoint in recovery only read certain transactions, also it allows other active transactions run when checkpointing.</p><a id="more"></a><h2 id="Failure-modes"><a href="#Failure-modes" class="headerlink" title="Failure modes"></a>Failure modes</h2><h3 id="Error-type"><a href="#Error-type" class="headerlink" title="Error type:"></a>Error type:</h3><ul><li><p>transaction failure: </p><p>  abort, error in application (like division<br>  by zero)</p></li><li><p>system failure: </p><p>  crash in DBMS, OS, hardware<br>  data in main memory is lost</p></li><li><p>media failure: </p><p>  head crash, catastrophy, data destroyed…</p></li></ul><p>==&gt; <strong>solution: logging</strong> record what have done to the database, <em>solve atomicity and durability</em></p><p>logging has three attributes, namely:</p><ul><li>rules</li><li>recovery methods</li><li>checkpoint</li></ul><h3 id="transactions-processing"><a href="#transactions-processing" class="headerlink" title="transactions processing"></a>transactions processing</h3><p>buffer manager, log manager</p><ol><li><p>transaction requests a database element from bufffer manager</p></li><li><p>buffermanager reqrieves from disk if needed</p></li><li><p>fetch element into local address space</p></li><li><p>modify or new element inside the address space</p></li><li><p>transaction returns new element to buffer manager</p></li><li><p>buffer manager writes element back to disk</p></li></ol><h3 id="primitive-operations"><a href="#primitive-operations" class="headerlink" title="primitive operations"></a>primitive operations</h3><ul><li><p>INPUT(X): copy X from disk into buffer</p></li><li><p>READ(X, t): Copy X from buffer into transaction address space</p></li><li><p>WRITE(X, t): copy value produced by t to element X</p></li><li><p>OUTPUT(X): copy containing X from buffer to disk</p></li></ul><h2 id="undo-logging"><a href="#undo-logging" class="headerlink" title="undo logging"></a>undo logging</h2><h3 id="log-records"><a href="#log-records" class="headerlink" title="log records:"></a>log records:</h3><ul><li><p>&lt; START T &gt;: start transaction T</p></li><li><p>&lt; T,X,v &gt;: the value v of database element X was changed by transaction T. (v is the history value)</p></li><li><p>&lt; COMMIT T &gt;: T complete, no further change</p></li><li><p>&lt; ABORT T &gt;: T has no effect on the disc</p></li><li><p>FLUSH LOG: ask buffer manager to write all log from blocks to disc</p></li></ul><p><strong><em>undo logging</em>: record past value v of &lt; T,X,v &gt;, recover to the history value, read log from bottle to the bottom until find the place where crashes happen.</strong></p><h3 id="Rules"><a href="#Rules" class="headerlink" title="Rules:"></a>Rules:</h3><ol><li><p><em>&lt; COMMIT T &gt; after OUTPUT(X) to the disc</em></p></li><li><p><em>record &lt; T,X,v &gt; after changes done, before write new changes to the disc</em></p></li></ol><h3 id="Recovery"><a href="#Recovery" class="headerlink" title="Recovery:"></a>Recovery:</h3><p>If crashes happen when:</p><ol><li><p>after FLUSH LOG —- do nothing because &lt; COMMIT T &gt; has been executed and changes in the disc</p></li><li><p>after &lt; COMMIT T&gt; before FLUSH LOG —- recovery to history value and write &lt; ABORT T &gt; to log then FLUSH LOG</p></li><li><p>write changes into disc —- take T as uncommitted, do same as above</p></li><li><p>record &lt; T,X,v &gt; —- do same as above </p></li></ol><h3 id="checkpoint"><a href="#checkpoint" class="headerlink" title="checkpoint"></a>checkpoint</h3><p>BUT: we can find that use undo logging we need to <strong>read all logs</strong>, it cost a lot</p><p>=&gt; So we use <strong>checkpoint</strong>, then we need to just recovery until we read &lt; CKPT &gt;</p><p>BUT: database is blocked during the checkpoint, no new transactions will be accepted</p><p>=&gt; checkpoint only for certain transactions, use &lt; START CKPT (T1, T2, … Tn) &gt; and <end ckpt=""></end></p><p>reading from back to first, if we meet:</p><ul><li><p>first &lt; END CKPT &gt; : recovery only till next &lt; START CKPT &gt;</p></li><li><p>first &lt; START CKPT T1, …Tk &gt;, means we have system failure during checkpointing, T1 … Tk are the single active transaction at this time</p></li></ul><h2 id="redo-logging"><a href="#redo-logging" class="headerlink" title="redo logging"></a>redo logging</h2><p><strong>record future value of an element, redo the changes</strong></p><h3 id="Rule"><a href="#Rule" class="headerlink" title="Rule:"></a>Rule:</h3><ol><li><p><em>use before write changes to disc</em></p></li><li><p><em>all logs of T and &lt; COMMIT T &gt; must be wrriten to disc</em></p></li></ol><h3 id="redo-recovery-process"><a href="#redo-recovery-process" class="headerlink" title="redo recovery process"></a>redo recovery process</h3><p>if crashes happen when:</p><ol><li><p>write to disc, namely after FLUSH LOG: T will be regarded as committed, so redo the changes as the redo log state (maybe redundant)</p></li><li><p>At &lt; COMMIT T &gt; : if &lt; COMMIT T &gt; write to the disc, same above, else same below</p></li><li><p>before &lt; COMMIT T &gt;: T is not complete, do nothing and &lt; ABORT T &gt;</p></li></ol><p>BUT: Although T is committed, it is possible that the change is not in the disc, namely crashes happen when OUTPUT.</p><p>=&gt; write all database elements on disc during checkpointing that have been changed by committed but incomplete transactions, don’t need to wait all active transactions finished.</p><h3 id="checkpoint-recovery"><a href="#checkpoint-recovery" class="headerlink" title="checkpoint recovery"></a>checkpoint recovery</h3><p>at &lt; END CKPT &gt;: All transactions committed before &lt; START CKPT (T1, T2,…, Tn) &gt; are on disc, but all T1 … Tk started after START are unsafe</p><p>at &lt; START CKPT … &gt;: crashes occurred during checkpointing, search next &lt; END CKPT &gt;(backward), then continue to next &lt; START CKPT … &gt;, redo all transactions.</p><p>redo after commit, if a transaction not commit, abort it.</p><h2 id="undo-vs-redo"><a href="#undo-vs-redo" class="headerlink" title="undo vs. redo"></a>undo vs. redo</h2><ul><li><p>undo logging: allowed to commit when all changes are on disk, write COMMIT to log after all values are on disk, log holds old values.<br><strong>Incomplete transactions are rolled back, complete transactions are ignored.</strong> </p></li><li><p>redo logging: allowed to commit when changes are on log, COMMIT is written to log before any value is written to disk, log holds new values.<br><strong>Incomplete transactions are ignored, complete transactions are repeated.</strong></p></li></ul><p>drawbacks: </p><ul><li><p>undo log: Data must be written immediately after the end of a transaction – too many I/O</p></li><li><p>redo log: All data stay in the buffer till COMMIT – high requirements of memory</p></li></ul><h2 id="undo-redo-logging"><a href="#undo-redo-logging" class="headerlink" title="undo/redo logging"></a>undo/redo logging</h2><p>flexible, but need to record more info in log.</p><p>&lt; T,X,v,w &gt;: (v is the old value, w is the new value)</p><p>Rule: Update log &lt; T,X,v,w &gt; must have been written to disc.</p><p>Before X changed by T has written on disc, &lt; COMMIT T &gt; can be written on disc before/after OUTPUT.</p><h3 id="Recovery-1"><a href="#Recovery-1" class="headerlink" title="Recovery"></a>Recovery</h3><p>Redo all committed transactions in time order.<br>Undo all uncommitted transactions in reverse time order.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>For Undo logging, do nothing to transactions committed, do undone to transactions uncommitted.<br>FOr Redo logging, do nothing to transactions uncommitted, do redone to transactions committed.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This chapter talks about how to do recovery when database system has crashes. To solve the atomicity and durability, we use logging. It mainly has Undo logging, Redo logging, and Undo/Redo logging. Undo logging records history value, commit after all changes write to the disk, ignore complete transactions; Redo logging records future value, commit before write to disk, ignore incomplete transactions and repeat complete transactions. We also use checkpoint in recovery only read certain transactions, also it allows other active transactions run when checkpointing.&lt;/p&gt;
    
    </summary>
    
      <category term="notes" scheme="http://yoursite.com/categories/notes/"/>
    
    
      <category term="TUBcourse" scheme="http://yoursite.com/tags/TUBcourse/"/>
    
      <category term="DatabaseTechnology" scheme="http://yoursite.com/tags/DatabaseTechnology/"/>
    
  </entry>
  
</feed>
