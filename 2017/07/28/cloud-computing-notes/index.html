<!doctype html>



  


<html class="theme-next mist use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="TUBcourse,CloudComputing," />





  <link rel="alternate" href="/atom.xml" title="Blackwhole" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="Cloud Computing Chapter1 – IntroductionConcepts of Cloud Computing✴️ Definitions of Cloud Computing according to NIST ✴️:  Cloud computing is a model for enabling ubiquitous, convenient , on-demand ne">
<meta name="keywords" content="TUBcourse,CloudComputing">
<meta property="og:type" content="article">
<meta property="og:title" content="cloud computing notes">
<meta property="og:url" content="http://yoursite.com/2017/07/28/cloud-computing-notes/index.html">
<meta property="og:site_name" content="Blackwhole">
<meta property="og:description" content="Cloud Computing Chapter1 – IntroductionConcepts of Cloud Computing✴️ Definitions of Cloud Computing according to NIST ✴️:  Cloud computing is a model for enabling ubiquitous, convenient , on-demand ne">
<meta property="og:locale" content="en">
<meta property="og:image" content="http://yoursite.com/home/hujin/图片/选区_002.png">
<meta property="og:image" content="http://yoursite.com/home/hujin/图片/选区_003.png">
<meta property="og:image" content="http://yoursite.com/home/hujin/图片/选区_004.png">
<meta property="og:updated_time" content="2017-11-28T00:48:41.848Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="cloud computing notes">
<meta name="twitter:description" content="Cloud Computing Chapter1 – IntroductionConcepts of Cloud Computing✴️ Definitions of Cloud Computing according to NIST ✴️:  Cloud computing is a model for enabling ubiquitous, convenient , on-demand ne">
<meta name="twitter:image" content="http://yoursite.com/home/hujin/图片/选区_002.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2017/07/28/cloud-computing-notes/"/>





  <title> cloud computing notes | Blackwhole </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Blackwhole</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
    
      <p class="site-subtitle"></p>
    
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-sitemap">
          <a href="/sitemap.xml" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-sitemap"></i> <br />
            
            Sitemap
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/07/28/cloud-computing-notes/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Jin HU">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="https://encrypted-tbn2.gstatic.com/images?q=tbn:ANd9GcTP_kGUi2GkujJOg5lq0k1sVJ98ewg1RoZjAWV7qMjfsoKIJFmq">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Blackwhole">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Blackwhole" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                cloud computing notes
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-07-28T14:38:44+02:00">
                2017-07-28
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/notes/" itemprop="url" rel="index">
                    <span itemprop="name">notes</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="Cloud-Computing-Chapter1-–-Introduction"><a href="#Cloud-Computing-Chapter1-–-Introduction" class="headerlink" title="Cloud Computing Chapter1 – Introduction"></a>Cloud Computing Chapter1 – Introduction</h1><h2 id="Concepts-of-Cloud-Computing"><a href="#Concepts-of-Cloud-Computing" class="headerlink" title="Concepts of Cloud Computing"></a>Concepts of Cloud Computing</h2><p><strong>✴️ Definitions of Cloud Computing according to NIST ✴️</strong>:  Cloud computing is a model for <em>enabling ubiquitous, convenient , on-demand network access</em> to a shared pool of configurable computing resources that can be <em>rapidly provisioned and released with minimal management effort or service provider interaction</em></p>
<a id="more"></a>
<p>Cloud model is composed of:</p>
<ul>
<li><p>Five essential characteristics</p>
<ul>
<li>On-demand self service: no human interaction required for resource provisioning(配置, supply with)</li>
<li>​Broad network access: accessible over network</li>
<li>Resource pooling: pooled resources dynamically shared among consumers, location independence</li>
<li>Rapid elasticity: Capabilities can be provisioned/released on demand</li>
<li>measured service: monitored resource usage</li>
</ul>
<p>资源配置不用人管，资源被监控、弹性分配和动态共享，可以广泛进入网络</p>
</li>
<li><p>🌟Three service models </p>
<ul>
<li>Software as a service(SaaS): application runs on cloud infrastructure, consumer access application over the network but doesn’t control/manage underlying infrastructure.</li>
<li>Platform as a Service(PaaS): Consumer deploy application onto cloud infrastructure using programming languages, libraries, tools supported by provider, no control over underlying infrastructure.</li>
<li>Infrastructure as a Service(IaaS): Provider provisions processing, storage, network resources to consumer, consumer has no control over underlying infrastructure 💠but can control OS, storage and deployed applications.</li>
</ul>
<p>SaaS是只能在云平台上跑应用，PaaS可以用服务商提供的工具部署应用，IaaS是服务商提供了所有基本的配置，三个服务模型都不能控制底层架构，但IaaS可以控制操作系统、存储和部署应用。定制化程度逐渐升高。</p>
</li>
<li><p>Four deployment models</p>
<ul>
<li>Private Cloud, used by single organization, owned by orgnization or third party or combination, no location premise</li>
<li>Community cloud, used by organizations with shared concerns, owned by organizations and third party or combination, no location premise</li>
<li>Public Cloud, open for public, owned by :business:business, 🏫academic, :government, organization and combination, location on premise of cloud provider</li>
<li>Hybrid Cloud, composition of private/community/public cloud.</li>
</ul>
</li>
</ul>
<h2 id="Main-Content-of-lecture"><a href="#Main-Content-of-lecture" class="headerlink" title="Main Content of lecture"></a>Main Content of lecture</h2><ol>
<li>Discussion of IaaS and PaaS: Understanding building blocks, performance characteristics</li>
<li>Writing scalable and fault-tolerant applications: How to run an application of hundreds of CPUs?</li>
</ol>
<p>Goal:</p>
<ul>
<li>Understanding the different levels of abstractions</li>
<li>Understanding the implications of resource sharing</li>
<li>Learning to take advantage of Cloud platforms</li>
</ul>
<h1 id="Cloud-Computing-Chapter-2-–-IaaS"><a href="#Cloud-Computing-Chapter-2-–-IaaS" class="headerlink" title="Cloud Computing Chapter 2 – IaaS"></a>Cloud Computing Chapter 2 – IaaS</h1><p>IaaS – Infrastructure as a Service</p>
<ul>
<li>Provider provisions processing, storage, network resources to consumer</li>
<li>Consumer does not control/manage underlying infrastructure but has control over operating systems, storage, and deployed applications</li>
</ul>
<p><em>challenges for IaaS provider</em>:</p>
<ol>
<li>Rapid provisioning: consumer can access to resource quickly</li>
<li>Elasticity: manage data center cost-efficiently, make resources appears infinite</li>
<li>Isolation: consumers have no interfere with each other</li>
<li>Performance: maintain good performance.</li>
</ol>
<p>对IaaS服务提供商的要求：consumer可以快速访问资源，有效管理资源，consumer间互不干扰，并维持高性能</p>
<p><em>an approach to deal with these challenges</em> –  <strong>virtualization</strong></p>
<ul>
<li>🆗 for rapid provisioning, virtualization can instantiated from pre-complied images, VMs also can be stored as logical volumes on SANs or simply as files. </li>
<li>🆗 for elasticity, virtualization statistical multiplexing creates illusion of unlimited resources. *customer also has incentive to release idle(闲置) resources</li>
<li>⛔️ for isolation, what degree of isolation can virtualization really provide? Are resources distributed in a fair manner?</li>
<li>⛔️ for performance, what is the overhead of virtualization? Can VMs compete with “bare-metal” systems?</li>
</ul>
<h2 id="Virtualization"><a href="#Virtualization" class="headerlink" title="Virtualization"></a>Virtualization</h2><p>Virtualization: <em>the simulation of the software and/or hardware upon which other software runs. This simulated environment is called a virtual machine.</em></p>
<p><em>Real system</em> is often referred as <em>host</em>.</p>
<p><em>Virtual system</em> is often referred as <em>guest</em>.</p>
<p>通过虚拟化技术将一台计算机虚拟为多台逻辑计算机</p>
<h3 id="virtualization-fundamentals"><a href="#virtualization-fundamentals" class="headerlink" title="virtualization fundamentals"></a>virtualization fundamentals</h3><p><strong>Virtualization can be regarded as a <em>translation</em> of host’s state to guest’s state, also operations.</strong></p>
<p>There is a isomophism $V$, maps guest state to host state. </p>
<p>virtualization can be classified as <em>Process Virtualization</em> and <em>System Virtualization</em>.</p>
<p><em>Process Virtualization</em>: application virtual machine, run as a normal application inside a host OS and supports a single process. It is created when that process is started and destroyed when it exits. Its purpose is to provide a platform-independent programming environment that abstracts away details of the underlying hardware or operating system, and allows a program to execute in the same way on any platform. <em>For example Wine software in Linux helps to run Windows application</em> .</p>
<p><em>System Virtualization</em>: provides a complete system platform which supports the execution of a complete operating system (OS),Just like you said <em>VirtualBox</em> is one example.</p>
<p><img src="/home/hujin/图片/选区_002.png" alt="选区_002"></p>
<p>进程虚拟化是指应用创建在主机host中，提供一个不依赖特定平台和底层硬件或os的编程环境，使程序可以在任何平台上跑。比如jvm</p>
<p>系统虚拟化提供了支持执行完整OS的平台。比如VirtualBox，里面可以开另外一个系统</p>
<h4 id="Platform-virtualization"><a href="#Platform-virtualization" class="headerlink" title="Platform virtualization"></a>Platform virtualization</h4><ol>
<li><p>Full Virtualization</p>
<p>全虚拟化是指虚拟机模拟了完整的底层硬件，包括处理器、物理内存、时钟、外设等，使得为原始硬件设计的操作系统或其它系统软件完全不做任何修改就可以在虚拟机中运行。</p>
</li>
<li><p>Paravirtualization</p>
<p>超虚拟化虚拟机中，部分硬件接口以软件的形式提供给客户机操作系统，这可以通过 Hypercall（VMM 提供给 Guest OS 的直接调用，与系统调用类似）的方式来提供</p>
</li>
<li><p>Hardware-Assisted Virtualization</p>
<p>硬件辅助虚拟化是指借助硬件（主要是主机处理器）的支持来实现高效的全虚拟化。</p>
</li>
<li><p>Partial Virtualization</p>
<p>VMM 只模拟部分底层硬件，因此客户机操作系统不做修改是无法在虚拟机中运行的，其它程序可能也需要进行修改。</p>
</li>
<li><p>Operating System Level Virtualization</p>
<p>操作系统级虚拟化是一种在服务器操作系统中使用的轻量级的虚拟化技术，内核通过创建多个虚拟的操作系统实例（内核和库）来隔离不同的进程，不同实例中的进程完全不了解对方的存在。</p>
</li>
</ol>
<h4 id="Two-basic-designs-for-hardware-virtualization"><a href="#Two-basic-designs-for-hardware-virtualization" class="headerlink" title="Two basic designs for hardware virtualization:"></a>Two basic designs for hardware virtualization:</h4><table>
<thead>
<tr>
<th>VMM type 1</th>
<th>VMM type 2</th>
</tr>
</thead>
<tbody>
<tr>
<td>bare-metal/ hypervisor virtualization</td>
<td>hosted virtualization</td>
</tr>
<tr>
<td>directly run on hardware</td>
<td>VMM as host OS process</td>
</tr>
<tr>
<td>basic OS to run schedule VMs</td>
<td>VMs run as processes supported by VMM</td>
</tr>
<tr>
<td>pro: more efficient</td>
<td>pro: no special drivers</td>
</tr>
<tr>
<td>con: require special device drivers</td>
<td>con: more overhead</td>
</tr>
</tbody>
</table>
<p>Conditions of VMM type I:</p>
<ul>
<li><p><strong>VMM must have ultimate control over hardware</strong></p>
</li>
<li><p><strong>Guest OS must be disempowered without noticing</strong></p>
</li>
<li><p>Four assumptions of Popek and Goldberg:</p>
<p>One processor and uniformly addressable memory</p>
<p>Two processor modes: system mode and user mode</p>
<p>Subset of instruction  set only available in system</p>
<p>Memory addressing is relative to relocation register</p>
</li>
</ul>
<h4 id="Categories-of-processor-instructions"><a href="#Categories-of-processor-instructions" class="headerlink" title="Categories of processor instructions:"></a>Categories of processor instructions:</h4><ul>
<li>Privileged instruction can only be executed in system mode</li>
<li>Sensitive instructions: Control-sensitive change configuration of resource, Behavior-sensitive instructions behave different depending on configuration of resource</li>
</ul>
<p><img src="/home/hujin/图片/选区_003.png" alt="选区_003"></p>
<p>Efficient VMM: all non-sensitive instructions run natively on processor.</p>
<p>Unprivileged instructions opearted on guest OS(user mode), when Privileged instructions appear, it traps to VMM(system mode), VMM emulates instruction operation, and jump to user target user mode.</p>
<p>Popek and Goldberg’s requirement are satisfied by IBM Power, Sun Sparc. </p>
<p>​:lightning: not satisfied by Intel IA-32. But virtualization on IA-32 is possible.  </p>
<h4 id="Virtualization-of-IA-32"><a href="#Virtualization-of-IA-32" class="headerlink" title="Virtualization of IA-32"></a>Virtualization of IA-32</h4><p>Instructions don’t trap, but have different semantics if not executed in system mode.</p>
<p>❓ IA-32 doesn’t satisfy Popek and Goldberg’s requirements, how can virtualization on IA-32 is possible? </p>
<p>IA-32 uses rings to manage privileges.</p>
<p><img src="/home/hujin/图片/选区_004.png" alt="选区_004"></p>
<ul>
<li>Full Virtualization using Binary Translation</li>
<li>OS-assisted virtualization</li>
<li>Hardware-assisted virtualization</li>
</ul>
<p>VT-x 为 IA 32 处理器增加了两种操作模式：VMX root operation 和 VMX non-root operation。VMM 自己运行在 VMX root operation 模式，VMX non-root operation 模式则由 Guest OS 使用。两种操作模式都支持 Ring 0 ~ Ring 3 这 4 个特权级，因此 VMM 和 Guest OS 都可以自由选择它们所期望的运行级别。</p>
<p><a href="https://www.ibm.com/developerworks/cn/linux/l-cn-vt/index.html" target="_blank" rel="external">source</a></p>
<p>virtualization of IA-32 architectures: full, OS-assisted, HW-assisted</p>
<h3 id="Full-Virtualization"><a href="#Full-Virtualization" class="headerlink" title="Full Virtualization"></a>Full Virtualization</h3><h4 id="Full-virtualization-using-binary-translation"><a href="#Full-virtualization-using-binary-translation" class="headerlink" title="Full virtualization using binary translation"></a>Full virtualization using binary translation</h4><p>translate a book word for word – inefficient</p>
<p>=&gt; Find critical instructions and replace them</p>
<ul>
<li>Run unprevileged instructions on CPU</li>
<li>Trap and emulate privileged and sensitive instructions</li>
<li>Find critical instructions and replace with exception</li>
</ul>
<p>translation is done lazily. Translation cache is good for frequently used translation units.</p>
<h5 id="Memory-Management"><a href="#Memory-Management" class="headerlink" title="Memory Management"></a>Memory Management</h5><p>MMU holds a Page Table to look up logical Page and Physical Page, translate logical to physical memory addresses.</p>
<p>However, page table reside in main memory, overhead of memory access doubles</p>
<p>每次都要访问主存，查询，取地址，开销很大</p>
<p>=&gt; Introduce special HW-accelerated cache to remember recent address translations – Translation Lookaside(后备) Buffer(TLB)</p>
<p>TLB acts as cache of MMU</p>
<p>​:lightning: TLB is invisible to OS, it is updated by hardware on every page table lookup, must be flushed on every context switch.</p>
<p>:light: Add another level of indirection</p>
<p>​:lightning: But additional memory access required to resolve address, inefficient</p>
<p>​=&gt;:light: Shadow page tables</p>
<p>guest OS maintain own page tables.</p>
<p>■ Modifications to guest’s page table trap<br>♦ Entry is copied to the VMM’s shadow page table<br>■ Shadow page table is actually used by hardware<br>♦ Keeps TLB up-to-date<br>♦ Works through virtualization of page table pointer</p>
<h5 id="Full-Virtualization-and-I-O"><a href="#Full-Virtualization-and-I-O" class="headerlink" title="Full Virtualization and I/O"></a>Full Virtualization and I/O</h5><p>Different levels of I/O virtualization possible:</p>
<table>
<thead>
<tr>
<th></th>
<th>content</th>
<th>pro</th>
<th>con</th>
<th>evaluation</th>
</tr>
</thead>
<tbody>
<tr>
<td>system call level</td>
<td>VMM intercepts system call at OS interface</td>
<td>VMM handles the entire I/O operation</td>
<td>VMM must shadow OS routines available to the user, Virt. must be transparent to the guest, needs to understand guest OS internals.</td>
<td>very complicated, hardly seen in practice</td>
</tr>
<tr>
<td>device driver level</td>
<td>VMM intercepts calls to virtual device driver</td>
<td>no “reverse engineering” required</td>
<td>requires knowledge of guest’s device driver interface</td>
<td>Not generally applicable, OK for many</td>
</tr>
<tr>
<td>I/O operation level</td>
<td>IA-32 provides special privileged instructions to talk to I/O devices</td>
<td>all I/O instructions trap</td>
<td>for low-level instructions, hard for VMM to determine concrete I/O operation, need “reverse engineering”</td>
<td>difficult for arbitrary devices</td>
</tr>
</tbody>
</table>
<h5 id="Summery-full-virtualization-with-binary-translation"><a href="#Summery-full-virtualization-with-binary-translation" class="headerlink" title="Summery full virtualization with binary translation"></a>Summery full virtualization with binary translation</h5><p>Don’t require modified guest OS</p>
<p>Don’t require hardware support</p>
<p>Good for compute-intensive applications, unprivileged instructions run directly on CPU.</p>
<p>Degraded performance for data-intensive applications, because I/O requires syscalls which is privileged instructions, “trap and emulate” requires context switches, also the switch will lead to complete flush of TLB</p>
<h5 id="VMWare-Adaptive-Binary-Translation"><a href="#VMWare-Adaptive-Binary-Translation" class="headerlink" title="VMWare Adaptive Binary Translation"></a>VMWare Adaptive Binary Translation</h5><p>Modern CPUs are deeply pipelined</p>
<p>Trapping privileged instructions can be too expensive</p>
<p>VMWare feature: Adaptive Binary Translation</p>
<ul>
<li>Monitor frequency and costs of traps</li>
<li>Adaptively switch between different execution strategies at runtime</li>
</ul>
<p>Adaptive Binary Translation improves speed over simpel “trap and emulate”</p>
<p>​:lightning: But some limitations remain:</p>
<ul>
<li>System calls always require VMM intervention(介入)</li>
<li>Many traps due to shadow table page mechanism</li>
<li>Instructions for I/O usually trap, context switch for VMM type II required</li>
</ul>
<h3 id="OS-assisted-Virtualization-paravirtualization"><a href="#OS-assisted-Virtualization-paravirtualization" class="headerlink" title="OS-assisted Virtualization(paravirtualization)"></a>OS-assisted Virtualization(paravirtualization)</h3><p>Idea:</p>
<ul>
<li>make guest OS aware that it is running in a VM</li>
<li>modify the guest source code so that it avoids assistance of the VMM as far as possible</li>
</ul>
<p>Requirements for pure OS-assisted approach</p>
<ul>
<li>Source code of guest OS is available</li>
<li>Modified guest OS maintains application binary interface</li>
</ul>
<h4 id="XEN-–-classic-representative-for-paravirtualization"><a href="#XEN-–-classic-representative-for-paravirtualization" class="headerlink" title="XEN  – classic representative for paravirtualization"></a>XEN  – classic representative for paravirtualization</h4><p>XEN architecture and domains:</p>
<p>Interfaces and Driver concept(XEN 1.0)</p>
<p>❓ How does XEN tackle full virtualization problems?</p>
<p>Critical instructions do not trap on IA-32</p>
<p>​    but guest OS is aware of virtualization</p>
<p>​    ➡️ so critical instructions can be avoided</p>
<p>Frequent intervention of the hypervisor required, mostly intervere on page table updates and system call</p>
<p>➡️ XEN cannot be without interventions either, but XEN plays some tricks to decrease frequency</p>
<ul>
<li>Static partitioning among domains</li>
<li>No guarantee partition is contiguous(邻近的)</li>
<li>Hypervisor knows which domain “owns” which pages</li>
</ul>
<h4 id="XEN-and-memory-virtualization"><a href="#XEN-and-memory-virtualization" class="headerlink" title="XEN and memory virtualization"></a>XEN and memory virtualization</h4><p>XEN lets guests maintain their own page tables which are visible to MMU, if guest OS knows its fraction of physic memory.</p>
<p>➡️ So no need for hypervisor intervention on read requests. XEN must only validate write requests to ensure isolation.</p>
<p>Procedure:</p>
<ol>
<li>Guest requests page table update via hypercall</li>
<li>XEN checks if mapping address belongs to domain</li>
<li>if ok, allows update to page table.</li>
</ol>
<p>XEN exists in top 64MB of every logical address space</p>
<p>​Kernel can access hypervisor without context switch ➡️ no TLB flush</p>
<p>​General <strong>XEN trick</strong>: command batching 命令批处理, which decreases number of required hypervisor entries/exists. Assume 1024 page table updates, for XEN, Requests collect, not processed immediately, submit with one hypercall ➡️ only one entry/exit required. But for full virtualization, needs 1024 entry/exit.</p>
<p>Application can call into guest OS without indirection through VMM(ring 0) on each call, because syscalls implemented through software exceptions.</p>
<ul>
<li>upon exceptions, HW consults HW exception table to find code to handle exception.</li>
<li>XEN allows guests to install “fast” exception handler in the hardware exception tale.</li>
<li>XEN validates handler before install them</li>
</ul>
<h4 id="XEN-and-I-O-virtualization"><a href="#XEN-and-I-O-virtualization" class="headerlink" title="XEN and I/O virtualization"></a>XEN and I/O virtualization</h4><p>XEN presents “idealized” hardware abstraction: XEN itself contains specific device drivers, domains only implements lightweight frontend driver.</p>
<p>I/O data transferred from guest via XEN using shared-memory, async buffer ring.</p>
<p>In XEN 1.0, device drivers are part of hypervisor: Wrong device drivers can cause system crashes, then virtulization may be affected.</p>
<p>In XEN 2.0, unmodified device drivers are now loaded in dedicated(专用的) “driver domains”, hypervisor only supervises access to hardware resources and ensure isolation.</p>
<h4 id="Summary-OS-Assisted-Virtualization"><a href="#Summary-OS-Assisted-Virtualization" class="headerlink" title="**Summary OS-Assisted Virtualization"></a>**Summary OS-Assisted Virtualization</h4><ul>
<li>​ Required modified guest OS(❓ what is modified guest OS)</li>
<li>don’t require hadware support</li>
<li>Pros: better performance through cooperation between hypervisor and guest OS</li>
<li>Cons: limited compatibility, increased management overhead for data center operator</li>
</ul>
<p>Currently, OS-Assisted virtualization is de-facto(事实上的) standard for I/O virtualization. XEN enjoys big support in cloud community.</p>
<p>All major virtualization solutions provide special drivers.</p>
<p>HW-assisted virt. became more important.</p>
<h3 id="Hardware-Assisted-Virtualization"><a href="#Hardware-Assisted-Virtualization" class="headerlink" title="Hardware-Assisted Virtualization"></a>Hardware-Assisted Virtualization</h3><p>Most virtualization difficulties caused by IA-32:</p>
<ul>
<li>sensitive instructions do not always trap in rings &gt; 0</li>
<li>guests can observe they are not running in ring 0</li>
</ul>
<p>➡️ extend IA-32 architecture to circumvent virtualization obstacles on the hardware level. (developed by Intel and AMD)</p>
<p>:surprise: HW support for virtualization keeps increasing</p>
<h4 id="First-generation-support-VT-x-AMD-V"><a href="#First-generation-support-VT-x-AMD-V" class="headerlink" title="First generation support (VT-x, AMD-V)"></a>First generation support (VT-x, AMD-V)</h4><p>CPU virtualization</p>
<p>VMM runs in root mode, Guest OS in guest mode. </p>
<p>VMM and guest run as “co-routines”, VMM can give CPU to guest OS(VM ENTER), also can decide conditions when to regain CPU(VM EXIT).</p>
<p>VMM controls guest through HW-defined structure, in Intel, it is VMCS, in AMD it is VMCB. (virtual machine control structure/block)</p>
<p>VMCS/VMCB contains:</p>
<ul>
<li>guest state</li>
<li>control bits defining conditions for VM EXIT</li>
<li>VMM uses control bits to “confine” and observe guest</li>
</ul>
<p>Benefits:</p>
<ul>
<li>VMM controls guest through VMCS in fine-grained way: Not all privileged instructions necessarily trap, VMM has flexibility to decide which instructions guest is allowed to handle itself.</li>
<li>HW extension eliminates many reasons for VMM intervention (like system calls, ring aliasing…)</li>
</ul>
<p>​:lightning: But interventions are still needed on several occasions: updates page table, context switches, I/O, interrupts</p>
<h4 id="Second-Generation-Support-MMU"><a href="#Second-Generation-Support-MMU" class="headerlink" title="Second Generation Support (MMU)"></a>Second Generation Support (MMU)</h4><p>Extended page tables (EPT) / Nested Page Tables(NPT) introduce HW support for memory virtualization.</p>
<p>Both Intel and AMD introduced tagged TLBs, every TLB entry associated with address space tag, only some entries are invalidated on context switch</p>
<p>(全虚拟化的TLB只有Logical address和physical address)</p>
<p>MMU 由 LA -&gt; RA 和RA-&gt;PA的在TLB的映射组成。</p>
<p>Benefits:</p>
<ul>
<li>Significantly less VMM intervention required<ul>
<li>page table updates, page faults, context switches require no VMM intervention</li>
</ul>
</li>
<li>No shadow page table memory overhead</li>
<li>Better scalability on multi-core CPUs</li>
</ul>
<p>Cost:</p>
<ul>
<li>High cost for TLB misses: $O(n^2), n = page\ table\ depth$ </li>
</ul>
<h4 id="Third-generation-support"><a href="#Third-generation-support" class="headerlink" title="Third generation support"></a>Third generation support</h4><p>focuses on I/O</p>
<p>Paravirtualization already decreased CPU overhead for I/O and increased data throughput(吞吐量),  because it have cooperation between virtualized device driver and VMM, and idealized interface reduced VMM interventions.</p>
<p>​:lightning: However, overhead still too high for high-performance apps</p>
<p>Goal for HW support:</p>
<ul>
<li>High-performance data transfer between device and guest</li>
<li>Isolation between guests</li>
</ul>
<h4 id="summary-HW-Assisted-Virtualization"><a href="#summary-HW-Assisted-Virtualization" class="headerlink" title="summary HW-Assisted Virtualization"></a>summary HW-Assisted Virtualization</h4><p>Not require modified guest OS</p>
<p>Need HW support</p>
<p>pros:</p>
<ul>
<li>improved performance even for unmodified guest OSs</li>
<li>good adaption of 1st generation HW-support by VMMs</li>
<li>2nd generation VMM support increasingly deployed</li>
</ul>
<p>cons:</p>
<ul>
<li>reduced flexibility due to HW constraints</li>
</ul>
<h3 id="Virtual-Machine-Migration"><a href="#Virtual-Machine-Migration" class="headerlink" title="Virtual Machine Migration"></a>Virtual Machine Migration</h3><p>Migration: move VM from one physical host to another</p>
<p>Why migration: </p>
<ul>
<li>Fault management</li>
<li>Maintenance</li>
<li>Load balancing</li>
</ul>
<p>Desired property:</p>
<ul>
<li>no shutdown of the VM</li>
<li>no distruption of the service</li>
<li>minimal impact for the user</li>
</ul>
<p>Memory migration: ensure <strong>consistency</strong> between source and destination</p>
<p>Local resources:</p>
<ul>
<li>network resources: maintain all open network connections, don’t rely on forwarding of resource host</li>
<li>storage resources: storage must be accessible both at source and destination</li>
</ul>
<h4 id="Strategies-for-Memory-migration"><a href="#Strategies-for-Memory-migration" class="headerlink" title="Strategies for Memory migration"></a>Strategies for Memory migration</h4><ol>
<li>​Push phase: source VM continues running, sends pages to destination, memory must potentially be sent multiple times ➡️ minimum downtime, potentially long migration time</li>
<li>​Stop-and-copy phase: Source VM stopped, pages copied to destination, destination is started after received all pages ➡️ short overall migration time, long downtime.</li>
<li>Pull phase: Execute new VM, pull accessed pages from source.</li>
</ol>
<h4 id="strategy-for-migration-in-XEN"><a href="#strategy-for-migration-in-XEN" class="headerlink" title="strategy for migration in XEN"></a>strategy for migration in XEN</h4><ol>
<li><p>memory migration</p>
<p>XEN pursues pre-copy strategy for memory migration, combine push and stop-and-copy, balances short downtime with short total migration time</p>
<p>Iterative approach: multiple rounds of push, short stop-and-copy in the end</p>
<p>VMWare vMotion use similar approatch.</p>
<p>Assumption: Source and destination VM are on same IP subnet</p>
</li>
<li><p>network migration</p>
<p>source and destination VM are on same IP subnet.</p>
<p>Approach:</p>
<ul>
<li>Dest. VM have new MAC but old IP address</li>
<li>After memory transfer, source host sends unsolicited ARP reply: broadcast msg to all hosts on the same network, hosts will remove IP ↔️MAC mapping from caches.</li>
<li>upon new ARP request, dest. VM will return new MAC address</li>
</ul>
</li>
<li><p>storage migration</p>
<p>XEN assumes VMs to reside on storage network, migration by rerouting network traffic, similar to network migration.</p>
</li>
</ol>
<h4 id="XEN-migration-timeline"><a href="#XEN-migration-timeline" class="headerlink" title="XEN migration timeline"></a>XEN migration timeline</h4><h3 id="Resource-Fairness-amp-Performance-Implications"><a href="#Resource-Fairness-amp-Performance-Implications" class="headerlink" title="Resource Fairness &amp; Performance Implications"></a>Resource Fairness &amp; Performance Implications</h3><p>In commercial IaaS clouds, many VMs often run on the same physical hardware.</p>
<p>❓ How is fairness enforced</p>
<p>Resource Distribution among VMs:</p>
<ul>
<li>Storage space: statically partitioned, each VM receives predefined fraction of disk</li>
<li>Main memory: statically partitioned, each VM receives predefined fraction of RAM</li>
<li>CPU: use Pinning (each VM is statically assigned CPU cores) or Schedualing (VMM dynamically assigns time slots to VMs)</li>
<li>I/O access: FCFS</li>
</ul>
<p>Since each VM want to receive “fair” share of CPU, to get high CPU utilization and low response time, available algorithms for CPU schedualing are: Borrowed Virtual Time, Atropos, Round RObin, sEDF scheduler, ARINC 653</p>
<p>​Though currently VM schedualing which focuses on CPU can get good fairness/response times, :lightning: However, processing I/O requests by VMM also consumes CPU time.</p>
<h3 id="Amazon-Elastic-Compute-Cloud-EC2"><a href="#Amazon-Elastic-Compute-Cloud-EC2" class="headerlink" title="Amazon Elastic Compute Cloud (EC2)"></a>Amazon Elastic Compute Cloud (EC2)</h3><p>Public IaaS cloud by AWS</p>
<p>Charges fee via per-hour pricing model, customer can shutdown VM at anytime. ➡️ No long-term obligations, no risk of over-/under-provisioning</p>
<h3 id="Summary-of-IaaS"><a href="#Summary-of-IaaS" class="headerlink" title="Summary of IaaS"></a>Summary of IaaS</h3><p>IaaS clouds let customers rent basic IT resources</p>
<ul>
<li>Full control over OS, storage and deployed applications</li>
<li>no long-term obligation or risk of over/under provisioning</li>
</ul>
<p>Virtualization as fundamental enabling technology</p>
<ul>
<li>Several customers can share physical infrastructure</li>
<li>Different approaches to achieve virtulization<ul>
<li>different levels of abstraction (full, OS-assisted, HW-assisted)</li>
<li>different performance overhead for different applications</li>
</ul>
</li>
</ul>
<h1 id="Cloud-computing-chapter-3-PaaS"><a href="#Cloud-computing-chapter-3-PaaS" class="headerlink" title="Cloud computing chapter 3 - PaaS"></a>Cloud computing chapter 3 - PaaS</h1><p>PaaS provide: Programming languages, Libraries, Services, Tools</p>
<p>Character of services:</p>
<ul>
<li>Consumer can deploy custom applications on PaaS cloud using provider’s model</li>
<li>doesn’t directly control the OS, storage, and deployed apps </li>
</ul>
<p>(Unlike Iaas, customization is lower)</p>
<p>Paas offers higher abstraction level than IaaS, less flexibility and higher provider dependence.</p>
<p>Charge by time/per query/per msg/CPU usage…</p>
<p>Consumers can deploy applications have very low operational costs until they become popular</p>
<p>PaaS value proposition:</p>
<ul>
<li>Maintenance: HW, OS, Middleware</li>
<li>Availability</li>
<li>Scalability</li>
</ul>
<h3 id="Fundamentals-for-scalable-availble-applications"><a href="#Fundamentals-for-scalable-availble-applications" class="headerlink" title="Fundamentals for scalable/availble applications"></a>Fundamentals for scalable/availble applications</h3><h4 id="How-to-Achieve-Scalability"><a href="#How-to-Achieve-Scalability" class="headerlink" title="How to Achieve Scalability?"></a>How to Achieve Scalability?</h4><p>Two principles to scale:</p>
<p>Multi-tier application scalability entails two questions:</p>
<ul>
<li>Where is the bottleneck?</li>
<li>Is the bottleneck component stateful or stateless?</li>
</ul>
<p><strong>Stateless components</strong>: component maintains no internal state beyond a request</p>
<p><strong>Stateful components</strong>: Component maintains state beyond request required to process next request</p>
<h5 id="scalability-with-stateless-components"><a href="#scalability-with-stateless-components" class="headerlink" title="scalability with stateless components"></a>scalability with stateless components</h5><p>Approach: <em>More instances of the bottlenect component</em></p>
<p>Possible levels of Stateless load balancing: Different levels LB can be combined</p>
<ol>
<li><p>Load balancing on IP level: Balancing is implemented by IP routers, multiple devices use one IP address, Routers route packet to different locations. Need request fit in one IP packet and control over routers. e.g.: DNS root server.</p>
</li>
<li><p>Load Balancing on DNS: implemented by DNS servers, DNS servers resolve DNS name to different IP addresses. Need control over DNS server and stable load characteristics.</p>
</li>
<li><p>Load Balancing by distinct load balancer: explicity distributes request among available machines, clients send requests to load balancer. require no network bottleneck.</p>
</li>
</ol>
<p>🔑 Strategies for stateless load balancing:</p>
<ol>
<li>Round robin LB: simple, good if all request cause roughtly the same load</li>
<li>Feedback-based LB: servers report actual load back to load balancer</li>
<li>Client-based LB: choose server with smallest network latency for client</li>
</ol>
<h5 id="Scalability-with-stateful-components"><a href="#Scalability-with-stateful-components" class="headerlink" title="Scalability with stateful components"></a>Scalability with stateful components</h5><p>We assume the data tier is the bottleneck</p>
<p>database is stateful, store data beyond request, requests from the same client must be handled by the same instance of the db server</p>
<p>​:light: Idea: Divide data into distinct independent parts, each server is responsible of one or more parts (Partitioning)</p>
<p>​:lightning: But pure partitioning is not helpful for availability</p>
<h4 id="Partitioning"><a href="#Partitioning" class="headerlink" title="Partitioning"></a>Partitioning</h4><p>❓ How to partition the data?</p>
<ul>
<li><p>Data is now spread across several machines</p>
</li>
<li><p>​A task may need data from different places servers together ➡️ causes network traffic</p>
</li>
<li><p>More machines add, Scacer the network resource is</p>
</li>
<li><p>The goal of every partitioning scheme is to reduce network communication </p>
<p>😢 however this is highly application-specific </p>
</li>
</ul>
<p>Partition schemes:</p>
<ol>
<li><p>Partitioning per tenant</p>
<p>​Put different tenant on different machines, it’s good for tenants to be isolated and no network traffic between machines. :lightning: But tenent cannot scale beyond one machine</p>
</li>
<li><p>Horizontal partitioning (relational databases)</p>
<p>Split tables by rows, put different rows on different machines, reduced number of rows, reduced indices. e.g.: Google Big Table, MongoDB</p>
</li>
<li><p>Vertical partitioning(relational databases)</p>
<p>split tables by columns, but not very common to improve scalability</p>
</li>
</ol>
<p>How to Distributed Data among Partitions?</p>
<ul>
<li>Define key attribute $k \in K$ on the data item to be stored</li>
<li>Define a globally-known partition function p so that $p: K \rightarrow P$ , $P$ is the set of available partitions</li>
<li>Characteristics of $p$ will influence load balancing and scability</li>
</ul>
<p>Classes of Partition Functions:</p>
<ul>
<li>Hash partitioning:<ul>
<li>Desired property: uniform distribution</li>
<li>Pro: Good load balancing characteristics</li>
<li>Con: inefficient for range queries, typically requires data reorganization when number of partitions changes.</li>
</ul>
</li>
<li>Range partitioning:<ul>
<li>Desired property: If $k_1, k_2 \in K$ are close, $p(k_1), p(k_2) \in P$ shall also be close to each other</li>
<li>Pro: Efficient for range queries and partition scaling</li>
<li>Con: Poor load balancing properties.</li>
</ul>
</li>
</ul>
<h4 id="Replication"><a href="#Replication" class="headerlink" title="Replication"></a>Replication</h4><p>​Data is only stored in one machine, if machine goes down, data is gone… ➡️ So we need availability.</p>
<p><em>Replication: Copies of the data on different machines</em> (where to place? who creates? what if data changes? How to deal with inconsistency?)</p>
<p><strong>Replication can improve both scalability and availability</strong></p>
<h5 id="Where-to-place-replicas"><a href="#Where-to-place-replicas" class="headerlink" title="Where to place replicas?"></a>Where to place replicas?</h5><p>In a cloud data center, replica placement depends on network hierarchy. </p>
<ul>
<li>one replica on another machine to prevent node failures</li>
<li>one replica on another rack(层) to prevent outages(service not available or equipment is closed down) of the rack switch</li>
</ul>
<p>In global scale, replicas are often distributed with regard to the client locations.</p>
<ul>
<li>Chosen to keep network transfers locally confined</li>
</ul>
<h5 id="Who-creates-the-copies"><a href="#Who-creates-the-copies" class="headerlink" title="Who creates the copies?"></a>Who creates the copies?</h5><ol>
<li><p>Server initiated replication</p>
<p>Copies created by server if popularity of data item increases, in order to reduce server load, server decides among a set of replica servers</p>
</li>
<li><p>Client-initiated replication(client caches)</p>
<p>replica created as result of client’s response, server has no control of cached copy, like web proxies.</p>
</li>
</ol>
<h5 id="What-happens-when-data-changes"><a href="#What-happens-when-data-changes" class="headerlink" title="What happens when data changes?"></a>What happens when data changes?</h5><ol>
<li>Invalidation protocols: If there are many updates and few reads, when data changed, inform replica servers that their replica is invalid now.</li>
<li>Transferring the modified data among servers: When many reads and few updates, each server can receive latest version immediately in this way.</li>
<li>Don’t send modified data, but modification commands: When commands substantially smaller than data, it’s good to use this method, also good when network bandwidth the scarse.</li>
</ol>
<p>Pull and Push based updates:</p>
<ul>
<li>When high degree of consistency is required, push-based updates is better. Servers can push updates to replica servers, mostly used in server-initiated replica setups.</li>
<li>When read-to-update ratio is low, pull-based updates is better. Clients request updates from server, often used by client caches.</li>
</ul>
<h5 id="How-to-deal-with-inconsistencies"><a href="#How-to-deal-with-inconsistencies" class="headerlink" title="How to deal with inconsistencies?"></a>How to deal with inconsistencies?</h5><p>When data in different locations, inconsistency can occur</p>
<p>Higher the consistency level, lower the performance</p>
<p>There must be a clear understanding what CL an app can expect from a replicated data store.</p>
<p>Consistency models: Contract between client and store</p>
<p>Two views of consistency models:</p>
<ol>
<li>Data-centric consistency models: from a global perspective, provides guarantees how a sequence of r/w operations are perceived by multiple clients</li>
<li>Client-centric consistency models: from a client’s perspective, provides guarantees how the state of a replicated data item is perceived by a single client.</li>
</ol>
<p>Data-centric consistency models:</p>
<ul>
<li><p>Strong consistency models: operations on shared data is synchronized (Strict\ Sequential \ Causal  Consistency)</p>
</li>
<li><p>Weak consistency models: Synchronization only when data is locked/unlocked (General week\ Release\ Entry Consistency)</p>
<p>​</p>
<p>Strict Consistency: any read to a shared data item x returns the value stored by the most recent write operation on x.</p>
</li>
</ul>
<p>​            (if follow strict consistency, client 2 read x just after client 1 write x. If don’t follow, client 2 can read another value of x which was before x wrote by client 1, 任何读操作都能读取到最新的修改，换句话说，要求任何写操作都立刻同步到其他所有进程。这里强调的是绝对时钟上的立刻同步，而任何信息的同步都需要延迟，因此在分布式系统下无法严格实现。)</p>
<p>​    ❓ Sequential Consistency: The result of any executions is the same as if the r/w operations of all processes were executed in some sequential order, and the operations of each individual process appear in this sequence in the order specified by its program.</p>
<p>Sequential Consistency将所有事件定一个全序，且单个进程内的多个操作满足program order，每个进程看到的都是这个全序。只要每个进程看到的定序结果是一致的，系统就是满足Sequential Consistency的。右图中client3和client4两个进程看到的读a和b的顺序不一致。</p>
<p>​    Causal Consistency:</p>
<p>Causal Consistency要求，如果两个事件有因果关系，则要求这两个事件的先后顺序满足因果序，并且所有进程看到的这两个事件的顺序都是满足这个因果序的。</p>
<p>Causal Consistency相比Sequential Consistency来说，仅要求有因果关系的事件顺序对所有进程看到的一致，没有因果关系的事件顺序对于所有进程可以不一致。</p>
<p>右图中client1对a的写操作和client2对b的写操作有因果关系，因此client3和client4读的时候要求顺序一致。</p>
<p>Client-centric consistency models:</p>
<p><a href="http://mark311.github.io/%E5%88%86%E5%B8%83%E5%BC%8F/%E6%9C%80%E7%BB%88%E4%B8%80%E8%87%B4%E6%80%A7/2014/10/18/eventually-consistent.html" target="_blank" rel="external">client-centric consistency</a></p>
<p>Eventual consistency: All replicas will eventually reach the most recent state, but clients may read old data and loose its own updates, implemented cheaply. 最终一致性，就是不保证在任意时刻任意节点上的同一份数据都是相同的，但是随着时间的迁移，不同节点上的同一份数据总是在向趋同的方向变化。也可以简单的理解为在一段时间后，节点间的数据会最终达到一致状态</p>
<p>1) Monotonic reads:</p>
<p>If a process reads x, any future reads on x by the process will returns the same or a more recent value</p>
<p>读到的数据总是不旧于上一次读到的数据。此种一致性要求如果Process A已经读取了对象的某个值，那么后续操作将不会读取到更早的值。</p>
<p>2) monotonic writes: 系统保证写操作由同一个进程执行。编写不提供这种一致性级别保证的系统是众所周知的困难</p>
<p>A write by a process on x is completed before any future write operations on x by the same process</p>
<p>3) Read your writes: 进程A更新一个数据项之后，再去访问它，总能得到更新后的值，并且不再会看到这个数据项更新之前的值。这是causal consistency模型的特殊形式。</p>
<p>A write by a process on x will be seen by a future read operation on x by the same process</p>
<p>4) writes follow reads:</p>
<p>A write by a process on x after a read on x takes place on the same or more recent value of x that was read</p>
<p>In general, the stricter the consistency model, the more it impacts the scability of a system.</p>
<ul>
<li>More consistency requires more synchronization</li>
<li>While the data is synchronized, some client requests may be answered</li>
</ul>
<p>Today’s cloud databases often sacrifice consistency for more scalability and availability.</p>
<h4 id="Brewer’s-CAP-theorem"><a href="#Brewer’s-CAP-theorem" class="headerlink" title="Brewer’s CAP theorem"></a>Brewer’s CAP theorem</h4><p>In a distributed system, it is <strong>impossible</strong> to provide three guarantees at the same time:</p>
<ul>
<li>Consistency: Write to one node, read from another node will return something no older than what was written</li>
<li>Availability: Non-failing node will send proper response</li>
<li>Partition tolerance: keep promise of either consistency or availablity in case of network partition.</li>
</ul>
<p>Illustrations of CAP:</p>
<ol>
<li>CA: provided all servers can communicate, e.g. Replicated DBMS</li>
<li>PC: System can provide even if some nodes are temporarily unreachble. e.g. pessimistic locking of distributed db.</li>
<li>AP: System tolerates network outages, it can still work even when some DNS servers are offline. e.g. DNS system</li>
</ol>
<h3 id="Case-Study"><a href="#Case-Study" class="headerlink" title="Case Study"></a>Case Study</h3><h4 id="Amazon-Dynamo"><a href="#Amazon-Dynamo" class="headerlink" title="Amazon Dynamo"></a>Amazon Dynamo</h4><p>Highly-available key-value store used inside Amazon</p>
<p>Sacrifices consistency to achieve high scalability, high availability, high performance and small latency.</p>
<p>Design principles:</p>
<ol>
<li>Follow Peer-To-Peer approach: every server is equal important, no single point of failure</li>
<li>Nodes can be added/removed incrementally at runtime: AP, weak consistency(eventual)</li>
<li>No hostile environment, all servers obey rules: no need to consider security issues.</li>
</ol>
<p>How to partition data among servers?</p>
<ul>
<li>​key-value store ➡️ no support for range queries needed, no need for range partitioning</li>
<li>hash partitioning has good load palancing properties</li>
<li>To avoid data reorganization when servers are added/removed, hash function no longer maps to partitions, instead functions maps to a fixed number of slots, it’s called <em>consistent hashing</em></li>
</ul>
<p>Consistent hashing: Additional mapping between slots and partitions</p>
<p>Distributed Hash tables</p>
<ul>
<li>each server takes at least one partition, therefore each server is responsible for a continuous range of slots, add/remove server only O(#key/#servers) data items must be reorganized</li>
</ul>
<p>:impressed: Amazon Dynamo’s partitioning algorithm: </p>
<p>To distribute data, key of data also hased with MD5, result of hashing is a position in the circular ID space.</p>
<p>Each server maintains full routing table (ID to IP)</p>
<ul>
<li>each server can determine which server is responsible for a data item based on routing table and mapping rule</li>
<li>one hop routin keeps latencies small</li>
</ul>
<p>Despite uniform distribution over ID space, the servers may receive skewed number of requests</p>
<p>:lightning: each server appears on multiple positions on the ring</p>
<p>Replication in Amazon Dynamo</p>
<ul>
<li>Servers replicate data to their N successors on the ring</li>
<li>r/w are allowed on every replica</li>
<li>replication is adjusted when a server is added/removed</li>
<li>Use heartbeat protocol to determine availability: periodic msg exchanged between ring neighbors, if a server doesn’t answer heartbeat request in a given time, it is considered gone.</li>
</ul>
<p>Data Version Reconciliation</p>
<p>Because Dynamo allows “always write” paradigm, different version of a data item may exist. Vector clocks are used to reconcile different versions.</p>
<h4 id="Microsoft-Azure"><a href="#Microsoft-Azure" class="headerlink" title="Microsoft Azure"></a>Microsoft Azure</h4><p>this PaaS platform was consisted of:</p>
<ul>
<li>Microsoft Azure: compute and storage services</li>
<li>SQL Azure: cloud-based DBMS</li>
<li>Azure AppFabric: tools to bridge gap between local and cloud-hosted apps</li>
</ul>
<p>Programming model: </p>
<ol>
<li>Azure applications separated into logical components, each components as assigned to a role. There are three roles:<ul>
<li>Web role: components facing outer world, accept requests via HTTP</li>
<li>Worker role: components doing background tasks</li>
<li>VM role: legacy components, component which cannot be converted to the pogramming model</li>
</ul>
</li>
<li>Each instance of a component is executed in a separate VM<ul>
<li>to improve maintainability and isolation</li>
<li>customer can choose between different types of VM</li>
<li>VM usage is billed by hour</li>
</ul>
</li>
</ol>
<p>Why different roles?</p>
<ul>
<li>To provide different levels of abstraction</li>
<li>But hardware and Microsoft Azure Hypervisor are the same across all roles</li>
</ul>
<p>Azure is basically a standard Windows environment, every programming language for Windows Server also runs on Azure.</p>
<p>Entry points into components:</p>
<ul>
<li>VM role entry point: precompiled VM image, Azure is agnostic(不可知的) of guest OS</li>
<li>Worker role entry point: Archive with intermediate code, code must implement particular interface</li>
<li>Web role entry point: Archive with web code</li>
</ul>
<p>How to achieve scalability?</p>
<ul>
<li><em>Run many instances of each role</em>, but instances of roles must be stateless.</li>
<li>Load balancers distribute requests between instances<ul>
<li>For web roles: HTTP load balancer for requests(round-robin distribution)</li>
<li>For worker roles: dependant on communication scheme</li>
</ul>
</li>
</ul>
<p>Azure offers distinct services to store state: Azure storage</p>
<ul>
<li>Table: abstraction similar to Excel sheet: <ul>
<li>Set of entities which are basic dataitems which composed of properties, which is part of an entity</li>
<li>Tables are partitioned horizontally, reads are load balanced across three replicas</li>
<li>Strong consistency</li>
<li>cost depend on total space occupied on storage services</li>
<li>Maximum size of a table is 100TB, Maximum size of entity is 1MB</li>
</ul>
</li>
<li>Blob: Key/value store for BLOB<ul>
<li>BLOB: single data item</li>
<li>Container: set of BLOBs</li>
<li>Max size of BLOB is 100TB, max size of a single BLOB is 50GB</li>
<li>Strong consistency</li>
<li>price similar to table storage</li>
</ul>
</li>
<li>Queue: Reliable msg delivery service between roles<ul>
<li>Does not gurantee FIFO and msg can be returned more than once</li>
</ul>
</li>
<li>SQL Azure: based on MS SQL Server<ul>
<li>Limited scalability compare to Table storage: size of db limited to 50 GB</li>
<li>Strong consistency</li>
<li>Billing per GB per month</li>
</ul>
</li>
</ul>
<p>Maintanence of Azure platform</p>
<p>​    deal with OS patches, middleware updates…</p>
<ul>
<li>Bring up new instance of role on new HW / patched OS image</li>
<li>Redeploy customer’s code</li>
<li>Register new instance with the load balancer</li>
<li>kill outdated instance</li>
<li>continue until all old instances have been replaced</li>
</ul>
<p>Three rules of the Azure programming model</p>
<ol>
<li>An Azure app is built from one or more roles</li>
<li>An Azure app runs multiple instances of each role: key to scalability and availability, allow Microsoft to silently update and restart instances</li>
<li>An Azure app behaves correctly when any role instance fails</li>
</ol>
<h4 id="Google-App-Engine"><a href="#Google-App-Engine" class="headerlink" title="Google App Engine"></a>Google App Engine</h4><p>Provide good response times to web clients</p>
<p>Provide APIs of multiple language to write and deploy web players</p>
<p>Automatic scale-out and scale-down according to changes of requests number</p>
<ul>
<li>Applications must not maintain internal state</li>
<li>Store any data in cloud storage services</li>
</ul>
<p>App Engine Datastore</p>
<ul>
<li><p>Reliable data store for key-value structured data</p>
</li>
<li><p>Builds upon two components:</p>
<ul>
<li>Google File System(GFS): distributed, scalable, fault-tolerant</li>
<li>Google Bigtable: flexibl, distributed storage for structured data</li>
</ul>
</li>
<li><p>GFS was designed to meet scalability, high performance, support for commodity HW, fault-tolerance</p>
</li>
<li><p>GFS design principles:</p>
<ul>
<li>limited support for random writes</li>
<li>data can be efficiently appended</li>
<li>sits on top of regular file systems</li>
<li>custom API to the developer</li>
</ul>
</li>
<li><p>GFS architecture</p>
<p>master-worker architecture. Master stores metadata, workers store actual data, called chunk server. Files are split into fixed-sized chunks, replicated across machines</p>
<p>When reading a file X from GFS:</p>
<ol>
<li>Client knows chunk size, converts offset to chunk index</li>
<li>client contacts master with filename and chunk index</li>
<li>master returns chunk handle and list of replicas</li>
<li>client sends read request to closest replica</li>
<li>client caches chunk handle so further reads of the same chunk require no more client-master interaction until cached information expires or file X is reopened.</li>
</ol>
<p>In this architecture, Master has global knowledge of the file system, which simplifies design and response times, make easy garbage collection and data reorganization.</p>
<p>Metadata is kept in main memory for performance, for each chunk, it consumes 64 bytes.</p>
<p>Chunk size is an important parameter of GFS, it determines the amount of metadata that fits into memory, and the frequency of the client requests.</p>
<p>If master fails, namespace/file-to-chunk mappings are written to log, this operation log is persistent on master’s hard disk and replicated to remote machine. Replica locations are requested from chunk servers when the master starts or new chunk server joins</p>
<p>Servers as logical timeline that defines the order of concurrent operations. Files and chunks are all uniquely and eternally identfied by their logical times of creation. Changes of file system are only visible to clients after the log has been flushed locally and remotely.</p>
<p>Master can recover FS state by replaying log.</p>
<p>A mutation (w/a) is performed at all the chunk’s replicas</p>
<p>Master grants chunk lease to one replica to ensure consistent mutation order across all the replicas</p>
<p>Primary choose serial order for mutations</p>
<p>GFS support for atomic appends. </p>
<p>​    Append is writing to a file at specific offset which traditionally specified by client. But in presense of two application concurrently specify to write record at offset Y, one record would be destroyed.</p>
<p>​    Special GFS operation to append data in atomic units. Operation guarantees that data is appended at least once. procedure:</p>
<ol>
<li><p>Client specifies append operation and data (but no offset!!)</p>
</li>
<li><p>Primary serializes requests, chooses offsets</p>
</li>
<li><p>returns offsets to client after data has been appended.</p>
<p>Data appended to next chunk if size exceeded otherwise</p>
<p>Client retries operation if appendent fails at any replica</p>
</li>
</ol>
</li>
<li><p>Google Bigtable</p>
<p>GFS offers tremendous storage capacity, but limitedd support to efficiently retrieve structured data.</p>
<p>​Solution ➡️ Google bigtable</p>
<ul>
<li>multi-dimensional sorted map</li>
<li>builds on top of the GFS</li>
<li>many use cases, backend for App Engine Datastore</li>
</ul>
<p>No schema, each row can have arbitrary columns, columns are grouped to column families.</p>
<p>Bigtable clusters stores several ables, a table consists of a set of tablets, tablet contains all data associated with a row range, each table has one tablet intially, when tablet grows, it is automatically split into several tablets.</p>
<p>Bigtable architecture:</p>
<p>​    Client sending requests (row, column, time), expecting value</p>
<p>​    Master can manage serveral tables, assigning tablets to tablet servers, keep track of addition/expiration of tablet servers, garbage collection, load balancing</p>
<p>​    tablets servers store actual tablets, serve client requests</p>
<p>Three-level hierarchy to locate correct tablet, client specifies table and row key, first lookup in root tablet. Information is stored in special METADATA tables.</p>
<p>Internal Tablet Structure:</p>
<p>​    Actual data is stored in a SSTable(sorted string table)</p>
<p>​    each SSTable consists of several blocks and index</p>
<p>Updates are stored to a commit log in GFS. Reads are served by merging memtable and SSTables</p>
<ul>
<li>Minor compaction: convert membtable into an SSTable, reduces memory usage and reconstruction effort of memtable on restart</li>
<li>Mergin compaction: reduce number of SSTables, happens periodically in the background</li>
<li>Major compaction: Merging compaction that results in only one SSTable, special case of merging compaction that purges deleted data.</li>
</ul>
</li>
</ul>
<h2 id="Cloud-computing-chapter-4-Data-Intensive-Applications-on-cloud-Architectures"><a href="#Cloud-computing-chapter-4-Data-Intensive-Applications-on-cloud-Architectures" class="headerlink" title="Cloud computing chapter 4 - Data-Intensive Applications on cloud Architectures"></a>Cloud computing chapter 4 - Data-Intensive Applications on cloud Architectures</h2><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>Amount of digitally available data grows rapidly</p>
<h4 id="Relation-Data-Intensive-Applications-clouds"><a href="#Relation-Data-Intensive-Applications-clouds" class="headerlink" title="Relation Data-Intensive Applications -clouds"></a>Relation Data-Intensive Applications -clouds</h4><ul>
<li>Requirements for data-intensive applications outscaled several traditional solutions: parallel databases are prohibitively expensive</li>
<li>Large sets fo commodity clusters are preferred: Data is stored on local hard disks, allows to keep computation close to the data</li>
<li>Individual commodity servers are less reliable. Data-intensive applications are typically elastic</li>
<li>Cloud computing often considered promising platform for data-intensive applications: looks like a large pool of clusters and customer, elastic platform, no large upfront capital expenses</li>
<li>However, virtualization overhead for I/O operations, no control over physical infrastructure</li>
</ul>
<p>Challenges of large-scale data processing</p>
<ul>
<li>Large clusters/clouds have 100s/1000s of servers, problem: high parallel environment</li>
<li>Writing efficient parallel applications at this scale is hard</li>
<li>needed: suitable abstraction layer for developers</li>
</ul>
<p>Abstraction layer for data-intensive applications:</p>
<ol>
<li>Developers don’t have to think about parallelization</li>
<li>Developers don’t have to think about fault tolerance</li>
<li>Developers don’t have to think about load balancing</li>
</ol>
<h3 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h3><p>Map and reduce take first-order functions as input, specify how data is passed to first-order function.</p>
<p>MapReduce operates on a key-value model.</p>
<p>Map function: first-order function provided by user, which specifies what happens to the data in job’s map phase</p>
<ul>
<li>signature: $(k_1, v_1) \rightarrow list(k_2, v_2)$</li>
<li>first-order functions is invoked once for each KV pair</li>
<li>useful for projections, selection…</li>
</ul>
<p>Reduce function: First-order function provided by user, specifies what happens to the data in job’s reducephase</p>
<ul>
<li>signature: $(k_2, v_2) \rightarrow list(k_2, v_2)$</li>
<li>all kv-pairs with the same key are presented to the same invocation of the first-order function</li>
<li>useful for aggregation, grouping…</li>
</ul>
<p>Mapper: a process running on a worker node, invokes map function for each KV pair</p>
<p>Reducer: process invoking reduce function on grouped data</p>
<h4 id="MapReduce-Implementation"><a href="#MapReduce-Implementation" class="headerlink" title="MapReduce Implementation"></a>MapReduce Implementation</h4><ul>
<li>Designed to run on large set of shared nothing servers</li>
<li>expects distributed file system, every node can potentially read every part of input</li>
<li>Individual nodes are likely to fail</li>
<li>Prefers local storage</li>
</ul>
<p>MapReduce follows master-worker pattern</p>
<ul>
<li>Master: responsible for job scheduling, monitor worker nodes, detect dead nodes, load balancing</li>
<li>Workers: execute map and reduce functions, store input/output data, periodically report availability to master node</li>
</ul>
<h4 id="Distributed-Execution-of-MapReduce-program"><a href="#Distributed-Execution-of-MapReduce-program" class="headerlink" title="Distributed Execution of MapReduce program"></a>Distributed Execution of MapReduce program</h4><ol>
<li>client partitions input file into input splits: splits define maximal scale-out, independent of GFS block size</li>
<li>Client submits job to master: includes code of map/reduce functions and list of input splits, master tries to find free resources to schedual mappers/reducers</li>
<li>Mapper started for each input splits: executing the user’s map function, multiple mappers per server possible, servers with replicas of input data preferred by the master, intermediate output of mappers is partitioned by intermediate key.</li>
<li>Reducers pull data from mappers over network</li>
</ol>
<p>refinements:</p>
<ul>
<li>can be used to locally aggregate intermediate results: executed after the mappers, it’s useful to unburden network. e.g. Example: If intermediate KV pair <for, 1="">, <for, 1=""> is created by the same mapper, the combiner aggregates it to <for, 2="">, without combiner <for, (1,1)=""> is shipped</for,></for,></for,></for,></li>
<li>Applicability of combiner depends on job</li>
</ul>
<h4 id="MapReduce-Fault-Tolerance"><a href="#MapReduce-Fault-Tolerance" class="headerlink" title="MapReduce Fault Tolerance"></a>MapReduce Fault Tolerance</h4><ul>
<li>if mapper fails: master detects failure through missing status report, mapper is restarted on different node, re-reads data from GFS</li>
<li>if reducer fails: detect through missing status report, reducer is restarted, pulls intermediate results for its partition from mappers again</li>
<li>entire worker fails: master re-schedules lost mappers and reducers, finished mappers may be restarted to recompute lost intermediate results</li>
</ul>
<h4 id="MapReduce-limitations"><a href="#MapReduce-limitations" class="headerlink" title="MapReduce limitations"></a>MapReduce limitations</h4><ol>
<li>assumes finite input which prevents streaming process, useful to respond to events without large delays</li>
<li>data between MR jobs must go to Google File System: detrimental for iterative algorithms</li>
</ol>
<h4 id="Map-Reduce-with-Stratosphere"><a href="#Map-Reduce-with-Stratosphere" class="headerlink" title="Map/Reduce with Stratosphere"></a>Map/Reduce with Stratosphere</h4><p>❓ how to improve the efficiency of massively parallel data processing on IaaS platforms?</p>
<p>extend elasticity, but face challenges that loss of control due to required virtualization</p>
<p>Stratosphere features:</p>
<ol>
<li>exploiting the cloud’s elasticity</li>
<li>detecting parallelization constraints</li>
<li>reduce I/O bottlenecks</li>
<li>Inferring physical network topologies</li>
</ol>
<h4 id="Amazon-Elastic-MapReduce"><a href="#Amazon-Elastic-MapReduce" class="headerlink" title="Amazon Elastic MapReduce"></a>Amazon Elastic MapReduce</h4><p>Cloud service for data-intensive applications introduced in 2009 as part of AWS</p>
<p>Job processing cycle on Amazon EMR</p>
<ol>
<li>Customer submits job through web interface:<ul>
<li>Job specification contains: location of input data on Amazon S3, MapReduce code, user libraries, parameters…, number virtual machiens to run the job, type of VM to run the job, Designated output location on Amazon S3</li>
</ul>
</li>
<li>Requested VM are started on EC2:<ul>
<li>Pricing model starts</li>
<li>Booted AMIs to preconfigured to start HDFS/Hadoop</li>
<li>Hadoop worker nodes automatically contact master</li>
</ul>
</li>
<li>MapReduce job is processed on rented VMs</li>
<li>After completion, EC2 instance are automatically shut down</li>
</ol>
<p>EMR and Elasticity</p>
<ul>
<li>EMR allows customers to adjust number of VMs while job is running, customer can monitor job</li>
</ul>
<p>​Problem:lightning: But VMs to be removed may store intermediate results in HDFS</p>
<p>➡️ HDFS expects node loss as result of HW failure. </p>
<p>Solution: EMR separates VMs in three distinct groups.</p>
<ol>
<li>Master group: contains only VM running MR master</li>
<li>Core group: VMs run Hadoop worker and HDFS node, the size of core group only can be increased</li>
<li>Task group: VMs only Hadoop worker, VMs store no local data, intermediate data is transferred to core group, size is flexible</li>
</ol>
<h3 id="Flink-and-Spark"><a href="#Flink-and-Spark" class="headerlink" title="Flink and Spark"></a>Flink and Spark</h3><p>MapReduce evolutions:</p>
<ul>
<li>need more operator: join, groupBys, filter… besides map and reduce</li>
<li>to simplify a wide array of computation: iterative ml, streaming, complex batch jobs</li>
<li>keep intermediate results in memory</li>
<li>Generalize processing engine to handle streams: use batch engine with small batch size/ use real streaming engine</li>
<li>Stream processing requires redefinition of operators: use window operators replace reduce function</li>
</ul>
<h4 id="Apache-Spark"><a href="#Apache-Spark" class="headerlink" title="Apache Spark"></a>Apache Spark</h4><h5 id="RDDs"><a href="#RDDs" class="headerlink" title="RDDs"></a>RDDs</h5><p>At Spark’s core are parallel transformations of Resilient Distributed Datasets(RDDs).</p>
<ul>
<li>RDDs are read-only collections of objects, distirbuted and partitioned across nodes, in-memory</li>
<li>Bulk operations transform RDDs in parallel on workers</li>
<li>RDDs are logical (lazy and ephemeral): run when they are used, contains enough information to compute it starting from data in reliable storage.</li>
<li>Fault-tolerance</li>
<li>cacheing: users can give command to keep RDDs in -memory</li>
<li>enables faster iterative jobs</li>
</ul>
<h5 id="Spark-streaming"><a href="#Spark-streaming" class="headerlink" title="Spark streaming"></a>Spark streaming</h5><p>spark processes continuous inputs as Microbatches</p>
<ul>
<li>arriving input is processed in batches which can be windows for operations.</li>
</ul>
<h4 id="Apache-Flink"><a href="#Apache-Flink" class="headerlink" title="Apache Flink"></a>Apache Flink</h4><p>A project to unify batch and stream processing in one engine. Flink’s core supports batch and streaming functions.</p>
<h5 id="Flink-execution-model"><a href="#Flink-execution-model" class="headerlink" title="Flink execution model"></a>Flink execution model</h5><p>A job consists of a directed acyclic graph(DAG) of oeprators and Intermediate streams of data records and control events flowing through the DAG of operators</p>
<p>follows a master-slave paradigm: job managers keeps track of all Task Managers and job execution.</p>
<p>A task manager will have one or more task slots.</p>
<p>complete DAG of operators are deployed distributed on all task managers: A task slot executes a pipeline of tasks, often execute successive operators concurrently</p>
<h5 id="Performance-comparison-of-streaming-approaches"><a href="#Performance-comparison-of-streaming-approaches" class="headerlink" title="Performance comparison of streaming approaches"></a>Performance comparison of streaming approaches</h5><ul>
<li><p>Micro batches: processing of small batches of tuples</p>
</li>
<li><p>“real” streaming: tuple-wise processing</p>
</li>
<li><p>Flink has lower latency: it processes an event as it becomes available</p>
</li>
</ul>
<h2 id="Cloud-computing-chapter5-Continuous-Integration"><a href="#Cloud-computing-chapter5-Continuous-Integration" class="headerlink" title="Cloud computing chapter5 - Continuous Integration"></a>Cloud computing chapter5 - Continuous Integration</h2><p>Developers(Dev) develop without knowledge of productive infrastructure</p>
<p>Operators(Ops) push code as a black box as they are not involved in development</p>
<p>​:lightning: conflicts: failure in server or in development?</p>
<p>➡️ Integrate both processes into continuous process</p>
<h3 id="Continuous-integration"><a href="#Continuous-integration" class="headerlink" title="Continuous integration"></a>Continuous integration</h3><p>Continuous Integration: integrating changes from different developers in the team into a mainline as early as possible</p>
<p>Continuous Development: keeping the application deployable at any point or even automatically releasing to a test or production. </p>
<p>Continuous Delivery: keeping the codebase deployable at any point and have all the configuration necessary to push it into production</p>
<p>■ Developers integrate code into a shared repository frequently (several times a day)<br>■ Each integration is verified by an automated build (including test) to detect integration errors as quickly as possible<br>​■ Small changes introduced to code ➡️ Quick detection and localization of failures possible</p>
<p>Principles of continuous integration:</p>
<ul>
<li>Maintain a single source repository which keeps track of all changes</li>
<li>Automate the builds</li>
<li>Make the build self-testing and keep the builds fast</li>
<li>Daily commits to the baseline by everyone on the team</li>
</ul>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>


    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/TUBcourse/" rel="tag"># TUBcourse</a>
          
            <a href="/tags/CloudComputing/" rel="tag"># CloudComputing</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/03/07/DAlg-notes-C7/" rel="next" title="Distributed Algorithms C7 -- Consistent snapshot">
                <i class="fa fa-chevron-left"></i> Distributed Algorithms C7 -- Consistent snapshot
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>

          
          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Overview
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="https://encrypted-tbn2.gstatic.com/images?q=tbn:ANd9GcTP_kGUi2GkujJOg5lq0k1sVJ98ewg1RoZjAWV7qMjfsoKIJFmq"
               alt="Jin HU" />
          <p class="site-author-name" itemprop="name">Jin HU</p>
          <p class="site-description motion-element" itemprop="description">If you don't have ability, you will wind up playing in a rock band.</p>
        </div>
        <nav class="site-state motion-element">
        
          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">11</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">1</span>
                <span class="site-state-item-name">categories</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">5</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/jinhu94" target="_blank" title="Github">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  Github
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.linkedin.com/in/jin-hu-349633138/" target="_blank" title="LinkedIn">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  LinkedIn
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Cloud-Computing-Chapter1-–-Introduction"><span class="nav-number">1.</span> <span class="nav-text">Cloud Computing Chapter1 – Introduction</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Concepts-of-Cloud-Computing"><span class="nav-number">1.1.</span> <span class="nav-text">Concepts of Cloud Computing</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Main-Content-of-lecture"><span class="nav-number">1.2.</span> <span class="nav-text">Main Content of lecture</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Cloud-Computing-Chapter-2-–-IaaS"><span class="nav-number">2.</span> <span class="nav-text">Cloud Computing Chapter 2 – IaaS</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Virtualization"><span class="nav-number">2.1.</span> <span class="nav-text">Virtualization</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#virtualization-fundamentals"><span class="nav-number">2.1.1.</span> <span class="nav-text">virtualization fundamentals</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Platform-virtualization"><span class="nav-number">2.1.1.1.</span> <span class="nav-text">Platform virtualization</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Two-basic-designs-for-hardware-virtualization"><span class="nav-number">2.1.1.2.</span> <span class="nav-text">Two basic designs for hardware virtualization:</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Categories-of-processor-instructions"><span class="nav-number">2.1.1.3.</span> <span class="nav-text">Categories of processor instructions:</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Virtualization-of-IA-32"><span class="nav-number">2.1.1.4.</span> <span class="nav-text">Virtualization of IA-32</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Full-Virtualization"><span class="nav-number">2.1.2.</span> <span class="nav-text">Full Virtualization</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Full-virtualization-using-binary-translation"><span class="nav-number">2.1.2.1.</span> <span class="nav-text">Full virtualization using binary translation</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Memory-Management"><span class="nav-number">2.1.2.1.1.</span> <span class="nav-text">Memory Management</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Full-Virtualization-and-I-O"><span class="nav-number">2.1.2.1.2.</span> <span class="nav-text">Full Virtualization and I/O</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Summery-full-virtualization-with-binary-translation"><span class="nav-number">2.1.2.1.3.</span> <span class="nav-text">Summery full virtualization with binary translation</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#VMWare-Adaptive-Binary-Translation"><span class="nav-number">2.1.2.1.4.</span> <span class="nav-text">VMWare Adaptive Binary Translation</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#OS-assisted-Virtualization-paravirtualization"><span class="nav-number">2.1.3.</span> <span class="nav-text">OS-assisted Virtualization(paravirtualization)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#XEN-–-classic-representative-for-paravirtualization"><span class="nav-number">2.1.3.1.</span> <span class="nav-text">XEN  – classic representative for paravirtualization</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#XEN-and-memory-virtualization"><span class="nav-number">2.1.3.2.</span> <span class="nav-text">XEN and memory virtualization</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#XEN-and-I-O-virtualization"><span class="nav-number">2.1.3.3.</span> <span class="nav-text">XEN and I/O virtualization</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Summary-OS-Assisted-Virtualization"><span class="nav-number">2.1.3.4.</span> <span class="nav-text">**Summary OS-Assisted Virtualization</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hardware-Assisted-Virtualization"><span class="nav-number">2.1.4.</span> <span class="nav-text">Hardware-Assisted Virtualization</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#First-generation-support-VT-x-AMD-V"><span class="nav-number">2.1.4.1.</span> <span class="nav-text">First generation support (VT-x, AMD-V)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Second-Generation-Support-MMU"><span class="nav-number">2.1.4.2.</span> <span class="nav-text">Second Generation Support (MMU)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Third-generation-support"><span class="nav-number">2.1.4.3.</span> <span class="nav-text">Third generation support</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#summary-HW-Assisted-Virtualization"><span class="nav-number">2.1.4.4.</span> <span class="nav-text">summary HW-Assisted Virtualization</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Virtual-Machine-Migration"><span class="nav-number">2.1.5.</span> <span class="nav-text">Virtual Machine Migration</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Strategies-for-Memory-migration"><span class="nav-number">2.1.5.1.</span> <span class="nav-text">Strategies for Memory migration</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#strategy-for-migration-in-XEN"><span class="nav-number">2.1.5.2.</span> <span class="nav-text">strategy for migration in XEN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#XEN-migration-timeline"><span class="nav-number">2.1.5.3.</span> <span class="nav-text">XEN migration timeline</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Resource-Fairness-amp-Performance-Implications"><span class="nav-number">2.1.6.</span> <span class="nav-text">Resource Fairness & Performance Implications</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Amazon-Elastic-Compute-Cloud-EC2"><span class="nav-number">2.1.7.</span> <span class="nav-text">Amazon Elastic Compute Cloud (EC2)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Summary-of-IaaS"><span class="nav-number">2.1.8.</span> <span class="nav-text">Summary of IaaS</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Cloud-computing-chapter-3-PaaS"><span class="nav-number">3.</span> <span class="nav-text">Cloud computing chapter 3 - PaaS</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Fundamentals-for-scalable-availble-applications"><span class="nav-number">3.0.1.</span> <span class="nav-text">Fundamentals for scalable/availble applications</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#How-to-Achieve-Scalability"><span class="nav-number">3.0.1.1.</span> <span class="nav-text">How to Achieve Scalability?</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#scalability-with-stateless-components"><span class="nav-number">3.0.1.1.1.</span> <span class="nav-text">scalability with stateless components</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Scalability-with-stateful-components"><span class="nav-number">3.0.1.1.2.</span> <span class="nav-text">Scalability with stateful components</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Partitioning"><span class="nav-number">3.0.1.2.</span> <span class="nav-text">Partitioning</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Replication"><span class="nav-number">3.0.1.3.</span> <span class="nav-text">Replication</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Where-to-place-replicas"><span class="nav-number">3.0.1.3.1.</span> <span class="nav-text">Where to place replicas?</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Who-creates-the-copies"><span class="nav-number">3.0.1.3.2.</span> <span class="nav-text">Who creates the copies?</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#What-happens-when-data-changes"><span class="nav-number">3.0.1.3.3.</span> <span class="nav-text">What happens when data changes?</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#How-to-deal-with-inconsistencies"><span class="nav-number">3.0.1.3.4.</span> <span class="nav-text">How to deal with inconsistencies?</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Brewer’s-CAP-theorem"><span class="nav-number">3.0.1.4.</span> <span class="nav-text">Brewer’s CAP theorem</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Case-Study"><span class="nav-number">3.0.2.</span> <span class="nav-text">Case Study</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Amazon-Dynamo"><span class="nav-number">3.0.2.1.</span> <span class="nav-text">Amazon Dynamo</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Microsoft-Azure"><span class="nav-number">3.0.2.2.</span> <span class="nav-text">Microsoft Azure</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Google-App-Engine"><span class="nav-number">3.0.2.3.</span> <span class="nav-text">Google App Engine</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Cloud-computing-chapter-4-Data-Intensive-Applications-on-cloud-Architectures"><span class="nav-number">3.1.</span> <span class="nav-text">Cloud computing chapter 4 - Data-Intensive Applications on cloud Architectures</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Motivation"><span class="nav-number">3.1.1.</span> <span class="nav-text">Motivation</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Relation-Data-Intensive-Applications-clouds"><span class="nav-number">3.1.1.1.</span> <span class="nav-text">Relation Data-Intensive Applications -clouds</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MapReduce"><span class="nav-number">3.1.2.</span> <span class="nav-text">MapReduce</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#MapReduce-Implementation"><span class="nav-number">3.1.2.1.</span> <span class="nav-text">MapReduce Implementation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Distributed-Execution-of-MapReduce-program"><span class="nav-number">3.1.2.2.</span> <span class="nav-text">Distributed Execution of MapReduce program</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#MapReduce-Fault-Tolerance"><span class="nav-number">3.1.2.3.</span> <span class="nav-text">MapReduce Fault Tolerance</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#MapReduce-limitations"><span class="nav-number">3.1.2.4.</span> <span class="nav-text">MapReduce limitations</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Map-Reduce-with-Stratosphere"><span class="nav-number">3.1.2.5.</span> <span class="nav-text">Map/Reduce with Stratosphere</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Amazon-Elastic-MapReduce"><span class="nav-number">3.1.2.6.</span> <span class="nav-text">Amazon Elastic MapReduce</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Flink-and-Spark"><span class="nav-number">3.1.3.</span> <span class="nav-text">Flink and Spark</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Apache-Spark"><span class="nav-number">3.1.3.1.</span> <span class="nav-text">Apache Spark</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#RDDs"><span class="nav-number">3.1.3.1.1.</span> <span class="nav-text">RDDs</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Spark-streaming"><span class="nav-number">3.1.3.1.2.</span> <span class="nav-text">Spark streaming</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Apache-Flink"><span class="nav-number">3.1.3.2.</span> <span class="nav-text">Apache Flink</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Flink-execution-model"><span class="nav-number">3.1.3.2.1.</span> <span class="nav-text">Flink execution model</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Performance-comparison-of-streaming-approaches"><span class="nav-number">3.1.3.2.2.</span> <span class="nav-text">Performance comparison of streaming approaches</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Cloud-computing-chapter5-Continuous-Integration"><span class="nav-number">3.2.</span> <span class="nav-text">Cloud computing chapter5 - Continuous Integration</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Continuous-integration"><span class="nav-number">3.2.1.</span> <span class="nav-text">Continuous integration</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jin HU</span>
</div>


<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>


        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  




  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  



  




	





  





  

  
      <!-- UY BEGIN -->
      <script type="text/javascript" src="http://v2.uyan.cc/code/uyan.js?uid="></script>
      <!-- UY END -->
  




  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

  


</body>
</html>
